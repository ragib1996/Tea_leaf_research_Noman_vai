{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10602688,"sourceType":"datasetVersion","datasetId":6527737}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow import keras\nfrom keras.models import Model\nfrom keras import layers\nfrom keras.layers import Dense, Input, BatchNormalization, Activation\nfrom keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n#from keras.applications.imagenet_utils import _obtain_input_shape\n#from keras.utils.data_utils import get_file\nfrom sklearn.model_selection import KFold\nfrom keras.datasets import mnist\nfrom PIL import Image\n# for creating a one hot vector for labels\n#from keras.utils import np_utils\nfrom IPython.display import display, Image\n#import the models\nfrom keras import Model\n#add layers\nfrom keras import layers\n#add optimizer\nfrom keras import optimizers\n#add loss function \nfrom keras import losses\nimport random\n\nimport keras\nimport numpy as np\nimport pandas as pd \nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport tensorflow.keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-30T09:01:50.556084Z","iopub.execute_input":"2025-01-30T09:01:50.556317Z","iopub.status.idle":"2025-01-30T09:02:03.003051Z","shell.execute_reply.started":"2025-01-30T09:01:50.556288Z","shell.execute_reply":"2025-01-30T09:02:03.002296Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from tensorflow import keras\nfrom keras.models import Model\nfrom keras.layers import Dense, Input, BatchNormalization, Activation\nfrom keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom IPython.core.display import display, HTML\nimport sys\n\n# Adjust notebook display width\ndisplay(HTML(\"<style>.container { width:90% !important; }</style>\"))\n\n\nimg_size = 299\ndef Xception():\n\n\t# Determine proper input shape\n\tinput_shape = (img_size, img_size, 3 )#_obtain_input_shape(None, default_size=299, min_size=71, data_format='channels_last', include_top=False)\n\n\timg_input = Input(shape=input_shape)\n\n\t# Block 1\n\tx = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False)(img_input)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = Conv2D(64, (3, 3), use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\n\tresidual = Conv2D(128, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n\tresidual = BatchNormalization()(residual)\n\n\t# Block 2\n\tx = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\n\t# Block 2 Pool\n\tx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\tx = layers.add([x, residual])\n\n\tresidual = Conv2D(256, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n\tresidual = BatchNormalization()(residual)\n\n\t# Block 3\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\n\t# Block 3 Pool\n\tx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\tx = layers.add([x, residual])\n\n\tresidual = Conv2D(728, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n\tresidual = BatchNormalization()(residual)\n\n\t# Block 4\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\n\tx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\tx = layers.add([x, residual])\n\n\t# Block 5 - 12\n\tfor i in range(8):\n\t\tresidual = x\n\n\t\tx = Activation('relu')(x)\n\t\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\t\tx = BatchNormalization()(x)\n\t\tx = Activation('relu')(x)\n\t\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\t\tx = BatchNormalization()(x)\n\t\tx = Activation('relu')(x)\n\t\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\t\tx = BatchNormalization()(x)\n\n\t\tx = layers.add([x, residual])\n\n\tresidual = Conv2D(1024, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n\tresidual = BatchNormalization()(residual)\n\n\t# Block 13\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(1024, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\n\t# Block 13 Pool\n\tx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\tx = layers.add([x, residual])\n\n\t# Block 14\n\tx = SeparableConv2D(1536, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\n\t# Block 14 part 2\n\tx = SeparableConv2D(2048, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\n\t# Fully Connected Layer\n\tx = GlobalAveragePooling2D()(x)\n\tx = Dense( 4 , activation='softmax')(x)\n\n\tinputs = img_input\n\n\t# Create model\n\tmodel = Model(inputs, x, name='xception')\n\n\t# Download and cache the Xception weights file\n\n\n\treturn model\n\nmodel = Xception()\n\nmodel.compile(\n    optimizer='Adam',\n    loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n    metrics=[\"accuracy\"],\n)\n\n# Print the model summary\nmodel.summary(print_fn=lambda x: sys.stdout.write(x + '\\n'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T09:02:03.004214Z","iopub.execute_input":"2025-01-30T09:02:03.004689Z","iopub.status.idle":"2025-01-30T09:02:05.939867Z","shell.execute_reply.started":"2025-01-30T09:02:03.004654Z","shell.execute_reply":"2025-01-30T09:02:05.936034Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>.container { width:90% !important; }</style>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"name":"stdout","text":"Model: \"xception\"\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃ Layer (type)              ┃ Output Shape           ┃        Param # ┃ Connected to           ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (InputLayer)  │ (None, 299, 299, 3)    │              0 │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d (Conv2D)           │ (None, 149, 149, 32)   │            864 │ input_layer[0][0]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization       │ (None, 149, 149, 32)   │            128 │ conv2d[0][0]           │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation (Activation)   │ (None, 149, 149, 32)   │              0 │ batch_normalization[0… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_1 (Conv2D)         │ (None, 147, 147, 64)   │         18,432 │ activation[0][0]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_1     │ (None, 147, 147, 64)   │            256 │ conv2d_1[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_1 (Activation) │ (None, 147, 147, 64)   │              0 │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d          │ (None, 147, 147, 128)  │          8,768 │ activation_1[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_3     │ (None, 147, 147, 128)  │            512 │ separable_conv2d[0][0] │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_2 (Activation) │ (None, 147, 147, 128)  │              0 │ batch_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_1        │ (None, 147, 147, 128)  │         17,536 │ activation_2[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_4     │ (None, 147, 147, 128)  │            512 │ separable_conv2d_1[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_2 (Conv2D)         │ (None, 74, 74, 128)    │          8,192 │ activation_1[0][0]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d             │ (None, 74, 74, 128)    │              0 │ batch_normalization_4… │\n│ (MaxPooling2D)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_2     │ (None, 74, 74, 128)    │            512 │ conv2d_2[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add (Add)                 │ (None, 74, 74, 128)    │              0 │ max_pooling2d[0][0],   │\n│                           │                        │                │ batch_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_3 (Activation) │ (None, 74, 74, 128)    │              0 │ add[0][0]              │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_2        │ (None, 74, 74, 256)    │         33,920 │ activation_3[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_6     │ (None, 74, 74, 256)    │          1,024 │ separable_conv2d_2[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_4 (Activation) │ (None, 74, 74, 256)    │              0 │ batch_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_3        │ (None, 74, 74, 256)    │         67,840 │ activation_4[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_7     │ (None, 74, 74, 256)    │          1,024 │ separable_conv2d_3[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_3 (Conv2D)         │ (None, 37, 37, 256)    │         32,768 │ add[0][0]              │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_1           │ (None, 37, 37, 256)    │              0 │ batch_normalization_7… │\n│ (MaxPooling2D)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_5     │ (None, 37, 37, 256)    │          1,024 │ conv2d_3[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_1 (Add)               │ (None, 37, 37, 256)    │              0 │ max_pooling2d_1[0][0], │\n│                           │                        │                │ batch_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_5 (Activation) │ (None, 37, 37, 256)    │              0 │ add_1[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_4        │ (None, 37, 37, 728)    │        188,672 │ activation_5[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_9     │ (None, 37, 37, 728)    │          2,912 │ separable_conv2d_4[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_6 (Activation) │ (None, 37, 37, 728)    │              0 │ batch_normalization_9… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_5        │ (None, 37, 37, 728)    │        536,536 │ activation_6[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_10    │ (None, 37, 37, 728)    │          2,912 │ separable_conv2d_5[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_4 (Conv2D)         │ (None, 19, 19, 728)    │        186,368 │ add_1[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_2           │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (MaxPooling2D)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_8     │ (None, 19, 19, 728)    │          2,912 │ conv2d_4[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_2 (Add)               │ (None, 19, 19, 728)    │              0 │ max_pooling2d_2[0][0], │\n│                           │                        │                │ batch_normalization_8… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_7 (Activation) │ (None, 19, 19, 728)    │              0 │ add_2[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_6        │ (None, 19, 19, 728)    │        536,536 │ activation_7[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_11    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_6[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_8 (Activation) │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_7        │ (None, 19, 19, 728)    │        536,536 │ activation_8[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_12    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_7[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_9 (Activation) │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_8        │ (None, 19, 19, 728)    │        536,536 │ activation_9[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_13    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_8[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_3 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│                           │                        │                │ add_2[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_10             │ (None, 19, 19, 728)    │              0 │ add_3[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_9        │ (None, 19, 19, 728)    │        536,536 │ activation_10[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_14    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_9[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_11             │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_10       │ (None, 19, 19, 728)    │        536,536 │ activation_11[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_15    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_10[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_12             │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_11       │ (None, 19, 19, 728)    │        536,536 │ activation_12[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_16    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_11[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_4 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│                           │                        │                │ add_3[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_13             │ (None, 19, 19, 728)    │              0 │ add_4[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_12       │ (None, 19, 19, 728)    │        536,536 │ activation_13[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_17    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_12[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_14             │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_13       │ (None, 19, 19, 728)    │        536,536 │ activation_14[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_18    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_13[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_15             │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_14       │ (None, 19, 19, 728)    │        536,536 │ activation_15[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_19    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_14[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_5 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│                           │                        │                │ add_4[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_16             │ (None, 19, 19, 728)    │              0 │ add_5[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_15       │ (None, 19, 19, 728)    │        536,536 │ activation_16[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_20    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_15[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_17             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_16       │ (None, 19, 19, 728)    │        536,536 │ activation_17[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_21    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_16[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_18             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_17       │ (None, 19, 19, 728)    │        536,536 │ activation_18[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_22    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_17[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_6 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│                           │                        │                │ add_5[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_19             │ (None, 19, 19, 728)    │              0 │ add_6[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_18       │ (None, 19, 19, 728)    │        536,536 │ activation_19[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_23    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_18[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_20             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_19       │ (None, 19, 19, 728)    │        536,536 │ activation_20[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_24    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_19[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_21             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_20       │ (None, 19, 19, 728)    │        536,536 │ activation_21[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_25    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_20[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_7 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│                           │                        │                │ add_6[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_22             │ (None, 19, 19, 728)    │              0 │ add_7[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_21       │ (None, 19, 19, 728)    │        536,536 │ activation_22[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_26    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_21[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_23             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_22       │ (None, 19, 19, 728)    │        536,536 │ activation_23[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_27    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_22[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_24             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_23       │ (None, 19, 19, 728)    │        536,536 │ activation_24[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_28    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_23[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_8 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│                           │                        │                │ add_7[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_25             │ (None, 19, 19, 728)    │              0 │ add_8[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_24       │ (None, 19, 19, 728)    │        536,536 │ activation_25[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_29    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_24[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_26             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_25       │ (None, 19, 19, 728)    │        536,536 │ activation_26[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_30    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_25[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_27             │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_26       │ (None, 19, 19, 728)    │        536,536 │ activation_27[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_31    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_26[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_9 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│                           │                        │                │ add_8[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_28             │ (None, 19, 19, 728)    │              0 │ add_9[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_27       │ (None, 19, 19, 728)    │        536,536 │ activation_28[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_32    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_27[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_29             │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_28       │ (None, 19, 19, 728)    │        536,536 │ activation_29[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_33    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_28[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_30             │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_29       │ (None, 19, 19, 728)    │        536,536 │ activation_30[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_34    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_29[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_10 (Add)              │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│                           │                        │                │ add_9[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_31             │ (None, 19, 19, 728)    │              0 │ add_10[0][0]           │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_30       │ (None, 19, 19, 728)    │        536,536 │ activation_31[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_36    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_30[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_32             │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_31       │ (None, 19, 19, 1024)   │        752,024 │ activation_32[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_37    │ (None, 19, 19, 1024)   │          4,096 │ separable_conv2d_31[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_5 (Conv2D)         │ (None, 10, 10, 1024)   │        745,472 │ add_10[0][0]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_3           │ (None, 10, 10, 1024)   │              0 │ batch_normalization_3… │\n│ (MaxPooling2D)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_35    │ (None, 10, 10, 1024)   │          4,096 │ conv2d_5[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_11 (Add)              │ (None, 10, 10, 1024)   │              0 │ max_pooling2d_3[0][0], │\n│                           │                        │                │ batch_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_32       │ (None, 10, 10, 1536)   │      1,582,080 │ add_11[0][0]           │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_38    │ (None, 10, 10, 1536)   │          6,144 │ separable_conv2d_32[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_33             │ (None, 10, 10, 1536)   │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_33       │ (None, 10, 10, 2048)   │      3,159,552 │ activation_33[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_39    │ (None, 10, 10, 2048)   │          8,192 │ separable_conv2d_33[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_34             │ (None, 10, 10, 2048)   │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d  │ (None, 2048)           │              0 │ activation_34[0][0]    │\n│ (GlobalAveragePooling2D)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (Dense)             │ (None, 4)              │          8,196 │ global_average_poolin… │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n Total params: 20,869,676 (79.61 MB)\n Trainable params: 20,815,148 (79.40 MB)\n Non-trainable params: 54,528 (213.00 KB)\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"x = []\nlabel = []\nx_validation = []\nlabel_validation = []\nx_test = []\nlabel_test = []\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T09:02:05.940952Z","iopub.execute_input":"2025-01-30T09:02:05.941195Z","iopub.status.idle":"2025-01-30T09:02:05.944973Z","shell.execute_reply.started":"2025-01-30T09:02:05.941172Z","shell.execute_reply":"2025-01-30T09:02:05.944032Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"csv_file = pd.read_csv(\"/kaggle/input/tea-image-dataset-nlmd-filtered/splited_into_5_fold.csv\")\nprint(csv_file)\n\nfolded = csv_file.groupby(\"fold\")\ntemp_image_name = \"\"\ntemp_image = []\nfor i,j in folded:\n    if i == 0: # testing\n        print(\"fold \"+str(i))\n        cat = j.groupby(\"category\")\n        for k,l in cat:\n            if k == \"Brown_blight\":\n                brown_blight_image_name = l['image_name']\n                brown_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Brown_blight\"\n                \n                for m in brown_blight_image_name:\n                    brown_blight_image = cv2.imread(brown_blight_link + '/'+\"nlmd_\"+m)\n                    brown_blight_image = cv2.resize( brown_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = brown_blight_image\n                    \"\"\"\n                    x_test.append(brown_blight_image)\n                    label_test.append([0])\n                print(len(x_test),\" \",len(label_test))\n                    \n            if k == \"Grey_blight\":\n                grey_blight_image_name = l['image_name']    \n                grey_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Grey_blight\"\n\n                for m in grey_blight_image_name:\n                    grey_blight_image = cv2.imread(grey_blight_link + '/'+\"nlmd_\"+m)\n                    grey_blight_image = cv2.resize( grey_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = grey_blight_image\n                    \"\"\"\n                    x_test.append(grey_blight_image)\n                    label_test.append([1])\n                print(len(x_test),\" \",len(label_test))\n                    \n            if k == \"Healthy\":\n                healthy_image_name = l['image_name']    \n                healthy_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Healthy\"\n\n                for m in healthy_image_name:\n                    healthy_image = cv2.imread(healthy_link + '/'+\"nlmd_\"+m)\n                    healthy_image = cv2.resize( healthy_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = healthy_image\n                    \"\"\"\n                    x_test.append( healthy_image)\n                    label_test.append([2])\n                print(len(x_test),\" \",len(label_test))\n\n            if k == \"Red_rust\":\n                red_rust_image_name = l['image_name']\n                red_rust_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Red_rust\"\n\n                for m in red_rust_image_name:\n                    red_rust_image = cv2.imread(red_rust_link+ '/' + \"nlmd_\"+m)\n                    red_rust_image = cv2.resize(red_rust_image, (img_size, img_size))\n                    x_test.append(red_rust_image)\n                    label_test.append([3])\n                print(len(x_test),\" \", len(label_test))\n            \n    \n    elif i == 1: # validation\n        print(\"fold \"+str(i))\n        cat = j.groupby(\"category\")\n        for k,l in cat:\n            if k == \"Brown_blight\":\n                brown_blight_image_name = l['image_name']\n                brown_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Brown_blight\"\n                \n                for m in brown_blight_image_name:\n                    brown_blight_image = cv2.imread(brown_blight_link + '/'+\"nlmd_\"+m)\n                    brown_blight_image = cv2.resize(brown_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = brown_blight_image\n                    \"\"\"\n                    x_validation.append(brown_blight_image)\n                    label_validation.append([0])\n                print(len(x_validation),\" \",len(label_validation))\n                    \n            if k == \"Grey_blight\":\n                grey_blight_image_name = l['image_name']    \n                grey_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Grey_blight\"\n\n                for m in grey_blight_image_name:\n                    grey_blight_image = cv2.imread(grey_blight_link + '/'+\"nlmd_\"+m)\n                    grey_blight_image = cv2.resize( grey_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = grey_blight_image\n                    \"\"\"\n                    x_validation.append(grey_blight_image)\n                    label_validation.append([1])\n                print(len(x_validation),\" \",len(label_validation))\n                    \n            if k == \"Healthy\":\n                healthy_image_name = l['image_name']    \n                healthy_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Healthy\"\n\n                for m in healthy_image_name:\n                    healthy_image = cv2.imread(healthy_link + '/'+\"nlmd_\"+m)\n                    healthy_image =  cv2.resize(healthy_image , ( img_size , img_size ))\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = healthy_image\n                    x_validation.append( healthy_image)\n                    label_validation.append([2])\n                print(len(x_validation),\" \",len(label_validation))\n                \n            if k == \"Red_rust\":\n                red_rust_image_name = l['image_name']\n                red_rust_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Red_rust\"\n\n                for m in red_rust_image_name:\n                    red_rust_image = cv2.imread(red_rust_link+ '/' + \"nlmd_\"+m)\n                    red_rust_image = cv2.resize(red_rust_image, (img_size, img_size))\n                    x_validation.append(red_rust_image)\n                    label_validation.append([3])\n                print(len(x_validation),\" \", len(label_validation))\n            \n\n    else: # training\n        print(\"fold \"+str(i))\n        cat = j.groupby(\"category\")\n        for k,l in cat:\n            if k == \"Brown_blight\":\n                brown_blight_image_name = l['image_name']\n                brown_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Brown_blight\"\n                \n                for m in brown_blight_image_name:\n                    brown_blight_image = cv2.imread(brown_blight_link + '/'+\"nlmd_\"+m)\n                    brown_blight_image = cv2.resize(brown_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = brown_blight_image\n                    \"\"\"\n                    x.append(brown_blight_image)\n                    label.append([0])\n                print(len(x),\" \",len(label))\n            if k == \"Grey_blight\":\n                grey_blight_image_name = l['image_name']    \n                grey_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Grey_blight\"\n\n                for m in grey_blight_image_name:\n                    grey_blight_image = cv2.imread(grey_blight_link + '/'+\"nlmd_\"+m)\n                    grey_blight_image = cv2.resize( grey_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = grey_blight_image\n                    \"\"\"\n                    x.append(grey_blight_image)\n                    label.append([1])\n                print(len(x),\" \",len(label))\n                    \n            if k == \"Healthy\":\n                healthy_image_name = l['image_name']    \n                healthy_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Healthy\"\n\n                for m in healthy_image_name:\n                    healthy_image = cv2.imread(healthy_link + '/'+\"nlmd_\"+m)\n                    healthy_image =  cv2.resize(healthy_image , ( img_size , img_size ))\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = healthy_image\n                    x.append( healthy_image)\n                    label.append([2])\n                print(len(x),\" \",len(label))\n                \n            if k == \"Red_rust\":\n                red_rust_image_name = l['image_name']\n                red_rust_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Red_rust\"\n\n                for m in red_rust_image_name:\n                    red_rust_image = cv2.imread(red_rust_link+ '/' + \"nlmd_\"+m)\n                    red_rust_image = cv2.resize(red_rust_image, (img_size, img_size))\n                    x.append(red_rust_image)\n                    label.append([3])\n                print(len(x),\" \", len(label))\n            \n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T09:02:05.945878Z","iopub.execute_input":"2025-01-30T09:02:05.946169Z","iopub.status.idle":"2025-01-30T09:05:31.510597Z","shell.execute_reply.started":"2025-01-30T09:02:05.946139Z","shell.execute_reply":"2025-01-30T09:05:31.509846Z"}},"outputs":[{"name":"stdout","text":"                 image_name  fold      category\n0      Training_img_280.jpg     0  Brown_blight\n1      Training_img_662.jpg     0  Brown_blight\n2      Training_img_651.jpg     0  Brown_blight\n3      Training_img_809.jpg     0  Brown_blight\n4      Training_img_546.jpg     0  Brown_blight\n...                     ...   ...           ...\n3229  Training_img_2989.jpg     4      Red_rust\n3230  Training_img_2880.jpg     4      Red_rust\n3231  Training_img_2693.jpg     4      Red_rust\n3232  Training_img_2997.jpg     4      Red_rust\n3233  Training_img_2993.jpg     4      Red_rust\n\n[3234 rows x 3 columns]\nfold 0\n159   159\n329   329\n491   491\n649   649\nfold 1\n159   159\n328   328\n490   490\n648   648\nfold 2\n158   158\n327   327\n489   489\n646   646\nfold 3\n804   804\n973   973\n1135   1135\n1292   1292\nfold 4\n1450   1450\n1619   1619\n1780   1780\n1937   1937\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"print(len(x),\" \",len(label))\nprint(len(x_validation),\" \",len(label_validation))\nprint(len(x_test),\" \",len(label_test))\nprint(\"Hello world.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T09:05:31.512719Z","iopub.execute_input":"2025-01-30T09:05:31.513052Z","iopub.status.idle":"2025-01-30T09:05:31.519905Z","shell.execute_reply.started":"2025-01-30T09:05:31.513027Z","shell.execute_reply":"2025-01-30T09:05:31.518943Z"}},"outputs":[{"name":"stdout","text":"1937   1937\n648   648\n649   649\nHello world.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"x = np.asarray(x)\nx_validation = np.asarray(x_validation)\nx_test = np.asarray(x_test)\n\nprint(len(x),\" \", len(x_validation),\" \", len(x_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T09:05:31.520844Z","iopub.execute_input":"2025-01-30T09:05:31.521160Z","iopub.status.idle":"2025-01-30T09:05:31.756730Z","shell.execute_reply.started":"2025-01-30T09:05:31.521128Z","shell.execute_reply":"2025-01-30T09:05:31.755846Z"}},"outputs":[{"name":"stdout","text":"1937   648   649\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical \n\nlabel = np.array(label)\nlabel = to_categorical(label , 4 )\nprint(len(label))\n\n\n\nlabel = np.array(label)\nlabel_validation = to_categorical(label_validation , 4 )\nprint(len(label_validation))\n\nlabel = np.array(label)\nlabel_test = to_categorical(label_test , 4 )\nprint(len(label_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T09:05:31.757692Z","iopub.execute_input":"2025-01-30T09:05:31.758069Z","iopub.status.idle":"2025-01-30T09:05:31.767855Z","shell.execute_reply.started":"2025-01-30T09:05:31.758035Z","shell.execute_reply":"2025-01-30T09:05:31.766964Z"}},"outputs":[{"name":"stdout","text":"1937\n648\n649\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"print(label[491])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T09:05:31.768617Z","iopub.execute_input":"2025-01-30T09:05:31.768935Z","iopub.status.idle":"2025-01-30T09:05:31.777265Z","shell.execute_reply.started":"2025-01-30T09:05:31.768901Z","shell.execute_reply":"2025-01-30T09:05:31.776560Z"}},"outputs":[{"name":"stdout","text":"[0. 0. 0. 1.]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"early_stop  = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience= 90 , verbose=0, mode='max')\n#check_point = tf.keras.callbacks.ModelCheckpoint('/kaggle/working/xception_tea_leaves_nlmd_filtered.h5', monitor='val_acc', save_best_only=True, mode='max')\ncheck_point = tf.keras.callbacks.ModelCheckpoint('/kaggle/working/xception_tea_leaves_nlmd_filtered_0_1.keras', monitor='val_accuracy', save_best_only=True, mode='max')\n\nhistory = model.fit(x , label , validation_data = (x_validation , label_validation ), epochs = 100 , callbacks=[early_stop, check_point])\n    \n\nprint(\"skip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T09:05:31.778036Z","iopub.execute_input":"2025-01-30T09:05:31.778297Z","iopub.status.idle":"2025-01-30T10:34:44.653749Z","shell.execute_reply.started":"2025-01-30T09:05:31.778268Z","shell.execute_reply":"2025-01-30T10:34:44.652783Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 2s/step - accuracy: 0.6186 - loss: 0.9711 - val_accuracy: 0.2608 - val_loss: 1.3859\nEpoch 2/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 879ms/step - accuracy: 0.8533 - loss: 0.4067 - val_accuracy: 0.2932 - val_loss: 1.3859\nEpoch 3/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 854ms/step - accuracy: 0.8636 - loss: 0.3181 - val_accuracy: 0.2500 - val_loss: 1.3867\nEpoch 4/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 853ms/step - accuracy: 0.8994 - loss: 0.2599 - val_accuracy: 0.2500 - val_loss: 1.4006\nEpoch 5/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 854ms/step - accuracy: 0.9039 - loss: 0.2692 - val_accuracy: 0.2269 - val_loss: 1.3925\nEpoch 6/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 880ms/step - accuracy: 0.9208 - loss: 0.2093 - val_accuracy: 0.3503 - val_loss: 1.3481\nEpoch 7/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 856ms/step - accuracy: 0.9438 - loss: 0.1545 - val_accuracy: 0.3287 - val_loss: 1.6758\nEpoch 8/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 879ms/step - accuracy: 0.9540 - loss: 0.1417 - val_accuracy: 0.3534 - val_loss: 1.6148\nEpoch 9/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 878ms/step - accuracy: 0.9374 - loss: 0.1543 - val_accuracy: 0.6759 - val_loss: 1.9743\nEpoch 10/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 858ms/step - accuracy: 0.9482 - loss: 0.1348 - val_accuracy: 0.6127 - val_loss: 2.0360\nEpoch 11/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 882ms/step - accuracy: 0.9631 - loss: 0.1056 - val_accuracy: 0.7716 - val_loss: 1.7527\nEpoch 12/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 880ms/step - accuracy: 0.9721 - loss: 0.0779 - val_accuracy: 0.8426 - val_loss: 0.4750\nEpoch 13/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 882ms/step - accuracy: 0.9712 - loss: 0.0946 - val_accuracy: 0.8596 - val_loss: 0.7124\nEpoch 14/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 855ms/step - accuracy: 0.9682 - loss: 0.1151 - val_accuracy: 0.7068 - val_loss: 1.4316\nEpoch 15/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 854ms/step - accuracy: 0.9788 - loss: 0.0624 - val_accuracy: 0.7778 - val_loss: 1.4490\nEpoch 16/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 854ms/step - accuracy: 0.9722 - loss: 0.0687 - val_accuracy: 0.5231 - val_loss: 3.9892\nEpoch 17/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 855ms/step - accuracy: 0.9772 - loss: 0.0742 - val_accuracy: 0.6852 - val_loss: 3.5981\nEpoch 18/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 856ms/step - accuracy: 0.9729 - loss: 0.0694 - val_accuracy: 0.8009 - val_loss: 0.8367\nEpoch 19/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 859ms/step - accuracy: 0.9824 - loss: 0.0538 - val_accuracy: 0.7793 - val_loss: 1.9936\nEpoch 20/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 878ms/step - accuracy: 0.9874 - loss: 0.0372 - val_accuracy: 0.8935 - val_loss: 0.3632\nEpoch 21/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 857ms/step - accuracy: 0.9810 - loss: 0.0448 - val_accuracy: 0.6698 - val_loss: 2.5766\nEpoch 22/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 877ms/step - accuracy: 0.9769 - loss: 0.0742 - val_accuracy: 0.9275 - val_loss: 0.2465\nEpoch 23/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 857ms/step - accuracy: 0.9900 - loss: 0.0339 - val_accuracy: 0.7207 - val_loss: 1.0802\nEpoch 24/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 854ms/step - accuracy: 0.9948 - loss: 0.0135 - val_accuracy: 0.8935 - val_loss: 0.4461\nEpoch 25/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 854ms/step - accuracy: 0.9811 - loss: 0.0565 - val_accuracy: 0.5139 - val_loss: 7.9400\nEpoch 26/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 855ms/step - accuracy: 0.9752 - loss: 0.0632 - val_accuracy: 0.8472 - val_loss: 0.7571\nEpoch 27/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 854ms/step - accuracy: 0.9808 - loss: 0.0484 - val_accuracy: 0.3179 - val_loss: 18.1130\nEpoch 28/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 877ms/step - accuracy: 0.9738 - loss: 0.0839 - val_accuracy: 0.9290 - val_loss: 0.3081\nEpoch 29/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 857ms/step - accuracy: 0.9759 - loss: 0.0772 - val_accuracy: 0.5525 - val_loss: 3.4599\nEpoch 30/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 855ms/step - accuracy: 0.9865 - loss: 0.0421 - val_accuracy: 0.7716 - val_loss: 2.0132\nEpoch 31/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 878ms/step - accuracy: 0.9879 - loss: 0.0387 - val_accuracy: 0.9414 - val_loss: 0.3110\nEpoch 32/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 857ms/step - accuracy: 0.9869 - loss: 0.0313 - val_accuracy: 0.8441 - val_loss: 0.7969\nEpoch 33/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 856ms/step - accuracy: 0.9879 - loss: 0.0310 - val_accuracy: 0.8333 - val_loss: 1.0308\nEpoch 34/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 877ms/step - accuracy: 0.9934 - loss: 0.0246 - val_accuracy: 0.9444 - val_loss: 0.2269\nEpoch 35/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 857ms/step - accuracy: 0.9931 - loss: 0.0237 - val_accuracy: 0.6003 - val_loss: 2.8070\nEpoch 36/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 856ms/step - accuracy: 0.9966 - loss: 0.0119 - val_accuracy: 0.8565 - val_loss: 0.7692\nEpoch 37/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 856ms/step - accuracy: 0.9942 - loss: 0.0166 - val_accuracy: 0.9228 - val_loss: 0.2918\nEpoch 38/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 859ms/step - accuracy: 0.9934 - loss: 0.0250 - val_accuracy: 0.9167 - val_loss: 0.4428\nEpoch 39/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 860ms/step - accuracy: 0.9932 - loss: 0.0239 - val_accuracy: 0.9383 - val_loss: 0.3299\nEpoch 40/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 859ms/step - accuracy: 0.9938 - loss: 0.0182 - val_accuracy: 0.8889 - val_loss: 0.3713\nEpoch 41/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 855ms/step - accuracy: 0.9974 - loss: 0.0154 - val_accuracy: 0.8488 - val_loss: 0.7765\nEpoch 42/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 855ms/step - accuracy: 0.9902 - loss: 0.0258 - val_accuracy: 0.7855 - val_loss: 1.6406\nEpoch 43/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 855ms/step - accuracy: 0.9879 - loss: 0.0326 - val_accuracy: 0.7315 - val_loss: 2.5348\nEpoch 44/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 857ms/step - accuracy: 0.9905 - loss: 0.0226 - val_accuracy: 0.8302 - val_loss: 0.8273\nEpoch 45/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 858ms/step - accuracy: 0.9801 - loss: 0.0593 - val_accuracy: 0.8117 - val_loss: 0.9166\nEpoch 46/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 858ms/step - accuracy: 0.9942 - loss: 0.0220 - val_accuracy: 0.9352 - val_loss: 0.3141\nEpoch 47/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 857ms/step - accuracy: 0.9884 - loss: 0.0304 - val_accuracy: 0.8364 - val_loss: 1.0683\nEpoch 48/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 855ms/step - accuracy: 0.9904 - loss: 0.0318 - val_accuracy: 0.9336 - val_loss: 0.3793\nEpoch 49/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 855ms/step - accuracy: 0.9856 - loss: 0.0459 - val_accuracy: 0.9105 - val_loss: 0.3835\nEpoch 50/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 856ms/step - accuracy: 0.9916 - loss: 0.0287 - val_accuracy: 0.9352 - val_loss: 0.3672\nEpoch 51/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 858ms/step - accuracy: 0.9940 - loss: 0.0232 - val_accuracy: 0.8210 - val_loss: 1.2889\nEpoch 52/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 860ms/step - accuracy: 0.9873 - loss: 0.0348 - val_accuracy: 0.5772 - val_loss: 3.2438\nEpoch 53/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 862ms/step - accuracy: 0.9957 - loss: 0.0194 - val_accuracy: 0.8086 - val_loss: 0.8358\nEpoch 54/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 858ms/step - accuracy: 0.9897 - loss: 0.0217 - val_accuracy: 0.9228 - val_loss: 0.2028\nEpoch 55/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 855ms/step - accuracy: 0.9848 - loss: 0.0492 - val_accuracy: 0.6219 - val_loss: 5.7775\nEpoch 56/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 854ms/step - accuracy: 0.9914 - loss: 0.0208 - val_accuracy: 0.9167 - val_loss: 0.4004\nEpoch 57/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 857ms/step - accuracy: 0.9974 - loss: 0.0175 - val_accuracy: 0.7809 - val_loss: 1.1131\nEpoch 58/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 859ms/step - accuracy: 0.9986 - loss: 0.0042 - val_accuracy: 0.9028 - val_loss: 0.4593\nEpoch 59/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 861ms/step - accuracy: 0.9960 - loss: 0.0132 - val_accuracy: 0.8472 - val_loss: 0.6143\nEpoch 60/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 856ms/step - accuracy: 0.9975 - loss: 0.0091 - val_accuracy: 0.4815 - val_loss: 4.4376\nEpoch 61/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 854ms/step - accuracy: 0.9958 - loss: 0.0116 - val_accuracy: 0.9244 - val_loss: 0.3113\nEpoch 62/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 856ms/step - accuracy: 0.9888 - loss: 0.0258 - val_accuracy: 0.9290 - val_loss: 0.3256\nEpoch 63/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 861ms/step - accuracy: 0.9974 - loss: 0.0093 - val_accuracy: 0.8843 - val_loss: 0.5440\nEpoch 64/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 858ms/step - accuracy: 0.9972 - loss: 0.0089 - val_accuracy: 0.9352 - val_loss: 0.2894\nEpoch 65/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 854ms/step - accuracy: 0.9993 - loss: 0.0058 - val_accuracy: 0.9090 - val_loss: 0.4041\nEpoch 66/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 854ms/step - accuracy: 0.9973 - loss: 0.0091 - val_accuracy: 0.9043 - val_loss: 0.3399\nEpoch 67/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 855ms/step - accuracy: 0.9987 - loss: 0.0070 - val_accuracy: 0.7593 - val_loss: 1.3701\nEpoch 68/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 860ms/step - accuracy: 0.9950 - loss: 0.0149 - val_accuracy: 0.8750 - val_loss: 0.4934\nEpoch 69/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 859ms/step - accuracy: 0.9867 - loss: 0.0443 - val_accuracy: 0.6667 - val_loss: 1.3064\nEpoch 70/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 857ms/step - accuracy: 0.9853 - loss: 0.0551 - val_accuracy: 0.8719 - val_loss: 0.5511\nEpoch 71/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 855ms/step - accuracy: 0.9961 - loss: 0.0169 - val_accuracy: 0.8071 - val_loss: 1.1340\nEpoch 72/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 855ms/step - accuracy: 0.9979 - loss: 0.0100 - val_accuracy: 0.8796 - val_loss: 0.6464\nEpoch 73/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 855ms/step - accuracy: 0.9897 - loss: 0.0199 - val_accuracy: 0.9398 - val_loss: 0.3978\nEpoch 74/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 855ms/step - accuracy: 0.9944 - loss: 0.0317 - val_accuracy: 0.9367 - val_loss: 0.3968\nEpoch 75/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 858ms/step - accuracy: 0.9951 - loss: 0.0202 - val_accuracy: 0.6034 - val_loss: 2.0149\nEpoch 76/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 857ms/step - accuracy: 0.9670 - loss: 0.1154 - val_accuracy: 0.8164 - val_loss: 0.7313\nEpoch 77/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 855ms/step - accuracy: 0.9841 - loss: 0.0769 - val_accuracy: 0.3889 - val_loss: 5.4063\nEpoch 78/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 854ms/step - accuracy: 0.9908 - loss: 0.0234 - val_accuracy: 0.3873 - val_loss: 6.5604\nEpoch 79/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 853ms/step - accuracy: 0.9989 - loss: 0.0073 - val_accuracy: 0.9429 - val_loss: 0.2613\nEpoch 80/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 878ms/step - accuracy: 0.9962 - loss: 0.0165 - val_accuracy: 0.9552 - val_loss: 0.1740\nEpoch 81/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 858ms/step - accuracy: 0.9946 - loss: 0.0156 - val_accuracy: 0.7546 - val_loss: 0.9570\nEpoch 82/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 857ms/step - accuracy: 0.9939 - loss: 0.0114 - val_accuracy: 0.9552 - val_loss: 0.1530\nEpoch 83/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 878ms/step - accuracy: 0.9959 - loss: 0.0143 - val_accuracy: 0.9583 - val_loss: 0.2078\nEpoch 84/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 876ms/step - accuracy: 0.9990 - loss: 0.0044 - val_accuracy: 0.9784 - val_loss: 0.1585\nEpoch 85/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 855ms/step - accuracy: 0.9931 - loss: 0.0169 - val_accuracy: 0.8935 - val_loss: 0.5212\nEpoch 86/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 858ms/step - accuracy: 0.9981 - loss: 0.0045 - val_accuracy: 0.7377 - val_loss: 2.7897\nEpoch 87/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 856ms/step - accuracy: 0.9934 - loss: 0.0205 - val_accuracy: 0.8519 - val_loss: 0.6022\nEpoch 88/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 855ms/step - accuracy: 0.9992 - loss: 0.0023 - val_accuracy: 0.9429 - val_loss: 0.2078\nEpoch 89/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 856ms/step - accuracy: 0.9972 - loss: 0.0162 - val_accuracy: 0.9599 - val_loss: 0.1656\nEpoch 90/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 860ms/step - accuracy: 0.9978 - loss: 0.0064 - val_accuracy: 0.9691 - val_loss: 0.1850\nEpoch 91/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 859ms/step - accuracy: 0.9966 - loss: 0.0069 - val_accuracy: 0.9630 - val_loss: 0.1781\nEpoch 92/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 858ms/step - accuracy: 0.9936 - loss: 0.0204 - val_accuracy: 0.8040 - val_loss: 1.7819\nEpoch 93/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 856ms/step - accuracy: 0.9952 - loss: 0.0162 - val_accuracy: 0.9059 - val_loss: 0.4392\nEpoch 94/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 854ms/step - accuracy: 0.9990 - loss: 0.0032 - val_accuracy: 0.9367 - val_loss: 0.3277\nEpoch 95/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 853ms/step - accuracy: 0.9932 - loss: 0.0239 - val_accuracy: 0.7500 - val_loss: 1.2575\nEpoch 96/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 854ms/step - accuracy: 0.9909 - loss: 0.0358 - val_accuracy: 0.3688 - val_loss: 10.5727\nEpoch 97/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 855ms/step - accuracy: 0.9797 - loss: 0.0789 - val_accuracy: 0.8302 - val_loss: 0.9552\nEpoch 98/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 858ms/step - accuracy: 0.9970 - loss: 0.0087 - val_accuracy: 0.8488 - val_loss: 0.7154\nEpoch 99/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 857ms/step - accuracy: 0.9966 - loss: 0.0108 - val_accuracy: 0.9244 - val_loss: 0.4865\nEpoch 100/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 855ms/step - accuracy: 0.9967 - loss: 0.0122 - val_accuracy: 0.9630 - val_loss: 0.1352\nskip\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"a = 5\nwhile(True):\n    a = 10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T10:34:44.655242Z","iopub.execute_input":"2025-01-30T10:34:44.655502Z"}},"outputs":[],"execution_count":null}]}