{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10602688,"sourceType":"datasetVersion","datasetId":6527737}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow import keras\nfrom keras.models import Model\nfrom keras import layers\nfrom keras.layers import Dense, Input, BatchNormalization, Activation\nfrom keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n#from keras.applications.imagenet_utils import _obtain_input_shape\n#from keras.utils.data_utils import get_file\nfrom sklearn.model_selection import KFold\nfrom keras.datasets import mnist\nfrom PIL import Image\n# for creating a one hot vector for labels\n#from keras.utils import np_utils\nfrom IPython.display import display, Image\n#import the models\nfrom keras import Model\n#add layers\nfrom keras import layers\n#add optimizer\nfrom keras import optimizers\n#add loss function \nfrom keras import losses\nimport random\n\nimport keras\nimport numpy as np\nimport pandas as pd \nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport tensorflow.keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-31T13:11:41.852049Z","iopub.execute_input":"2025-01-31T13:11:41.852246Z","iopub.status.idle":"2025-01-31T13:12:01.396605Z","shell.execute_reply.started":"2025-01-31T13:11:41.852227Z","shell.execute_reply":"2025-01-31T13:12:01.395686Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from tensorflow import keras\nfrom keras.models import Model\nfrom keras.layers import Dense, Input, BatchNormalization, Activation\nfrom keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom IPython.core.display import display, HTML\nimport sys\n\n# Adjust notebook display width\ndisplay(HTML(\"<style>.container { width:90% !important; }</style>\"))\n\n\nimg_size = 299\ndef Xception():\n\n\t# Determine proper input shape\n\tinput_shape = (img_size, img_size, 3 )#_obtain_input_shape(None, default_size=299, min_size=71, data_format='channels_last', include_top=False)\n\n\timg_input = Input(shape=input_shape)\n\n\t# Block 1\n\tx = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False)(img_input)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = Conv2D(64, (3, 3), use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\n\tresidual = Conv2D(128, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n\tresidual = BatchNormalization()(residual)\n\n\t# Block 2\n\tx = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\n\t# Block 2 Pool\n\tx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\tx = layers.add([x, residual])\n\n\tresidual = Conv2D(256, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n\tresidual = BatchNormalization()(residual)\n\n\t# Block 3\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\n\t# Block 3 Pool\n\tx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\tx = layers.add([x, residual])\n\n\tresidual = Conv2D(728, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n\tresidual = BatchNormalization()(residual)\n\n\t# Block 4\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\n\tx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\tx = layers.add([x, residual])\n\n\t# Block 5 - 12\n\tfor i in range(8):\n\t\tresidual = x\n\n\t\tx = Activation('relu')(x)\n\t\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\t\tx = BatchNormalization()(x)\n\t\tx = Activation('relu')(x)\n\t\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\t\tx = BatchNormalization()(x)\n\t\tx = Activation('relu')(x)\n\t\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\t\tx = BatchNormalization()(x)\n\n\t\tx = layers.add([x, residual])\n\n\tresidual = Conv2D(1024, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n\tresidual = BatchNormalization()(residual)\n\n\t# Block 13\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(1024, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\n\t# Block 13 Pool\n\tx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\tx = layers.add([x, residual])\n\n\t# Block 14\n\tx = SeparableConv2D(1536, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\n\t# Block 14 part 2\n\tx = SeparableConv2D(2048, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\n\t# Fully Connected Layer\n\tx = GlobalAveragePooling2D()(x)\n\tx = Dense( 4 , activation='softmax')(x)\n\n\tinputs = img_input\n\n\t# Create model\n\tmodel = Model(inputs, x, name='xception')\n\n\t# Download and cache the Xception weights file\n\n\n\treturn model\n\nmodel = Xception()\n\nmodel.compile(\n    optimizer='Adam',\n    loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n    metrics=[\"accuracy\"],\n)\n\n# Print the model summary\nmodel.summary(print_fn=lambda x: sys.stdout.write(x + '\\n'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T13:12:01.397515Z","iopub.execute_input":"2025-01-31T13:12:01.398137Z","iopub.status.idle":"2025-01-31T13:12:05.640759Z","shell.execute_reply.started":"2025-01-31T13:12:01.398112Z","shell.execute_reply":"2025-01-31T13:12:05.639649Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>.container { width:90% !important; }</style>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"name":"stdout","text":"Model: \"xception\"\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃ Layer (type)              ┃ Output Shape           ┃        Param # ┃ Connected to           ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (InputLayer)  │ (None, 299, 299, 3)    │              0 │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d (Conv2D)           │ (None, 149, 149, 32)   │            864 │ input_layer[0][0]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization       │ (None, 149, 149, 32)   │            128 │ conv2d[0][0]           │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation (Activation)   │ (None, 149, 149, 32)   │              0 │ batch_normalization[0… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_1 (Conv2D)         │ (None, 147, 147, 64)   │         18,432 │ activation[0][0]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_1     │ (None, 147, 147, 64)   │            256 │ conv2d_1[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_1 (Activation) │ (None, 147, 147, 64)   │              0 │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d          │ (None, 147, 147, 128)  │          8,768 │ activation_1[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_3     │ (None, 147, 147, 128)  │            512 │ separable_conv2d[0][0] │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_2 (Activation) │ (None, 147, 147, 128)  │              0 │ batch_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_1        │ (None, 147, 147, 128)  │         17,536 │ activation_2[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_4     │ (None, 147, 147, 128)  │            512 │ separable_conv2d_1[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_2 (Conv2D)         │ (None, 74, 74, 128)    │          8,192 │ activation_1[0][0]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d             │ (None, 74, 74, 128)    │              0 │ batch_normalization_4… │\n│ (MaxPooling2D)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_2     │ (None, 74, 74, 128)    │            512 │ conv2d_2[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add (Add)                 │ (None, 74, 74, 128)    │              0 │ max_pooling2d[0][0],   │\n│                           │                        │                │ batch_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_3 (Activation) │ (None, 74, 74, 128)    │              0 │ add[0][0]              │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_2        │ (None, 74, 74, 256)    │         33,920 │ activation_3[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_6     │ (None, 74, 74, 256)    │          1,024 │ separable_conv2d_2[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_4 (Activation) │ (None, 74, 74, 256)    │              0 │ batch_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_3        │ (None, 74, 74, 256)    │         67,840 │ activation_4[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_7     │ (None, 74, 74, 256)    │          1,024 │ separable_conv2d_3[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_3 (Conv2D)         │ (None, 37, 37, 256)    │         32,768 │ add[0][0]              │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_1           │ (None, 37, 37, 256)    │              0 │ batch_normalization_7… │\n│ (MaxPooling2D)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_5     │ (None, 37, 37, 256)    │          1,024 │ conv2d_3[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_1 (Add)               │ (None, 37, 37, 256)    │              0 │ max_pooling2d_1[0][0], │\n│                           │                        │                │ batch_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_5 (Activation) │ (None, 37, 37, 256)    │              0 │ add_1[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_4        │ (None, 37, 37, 728)    │        188,672 │ activation_5[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_9     │ (None, 37, 37, 728)    │          2,912 │ separable_conv2d_4[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_6 (Activation) │ (None, 37, 37, 728)    │              0 │ batch_normalization_9… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_5        │ (None, 37, 37, 728)    │        536,536 │ activation_6[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_10    │ (None, 37, 37, 728)    │          2,912 │ separable_conv2d_5[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_4 (Conv2D)         │ (None, 19, 19, 728)    │        186,368 │ add_1[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_2           │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (MaxPooling2D)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_8     │ (None, 19, 19, 728)    │          2,912 │ conv2d_4[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_2 (Add)               │ (None, 19, 19, 728)    │              0 │ max_pooling2d_2[0][0], │\n│                           │                        │                │ batch_normalization_8… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_7 (Activation) │ (None, 19, 19, 728)    │              0 │ add_2[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_6        │ (None, 19, 19, 728)    │        536,536 │ activation_7[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_11    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_6[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_8 (Activation) │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_7        │ (None, 19, 19, 728)    │        536,536 │ activation_8[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_12    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_7[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_9 (Activation) │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_8        │ (None, 19, 19, 728)    │        536,536 │ activation_9[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_13    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_8[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_3 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│                           │                        │                │ add_2[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_10             │ (None, 19, 19, 728)    │              0 │ add_3[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_9        │ (None, 19, 19, 728)    │        536,536 │ activation_10[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_14    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_9[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_11             │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_10       │ (None, 19, 19, 728)    │        536,536 │ activation_11[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_15    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_10[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_12             │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_11       │ (None, 19, 19, 728)    │        536,536 │ activation_12[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_16    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_11[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_4 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│                           │                        │                │ add_3[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_13             │ (None, 19, 19, 728)    │              0 │ add_4[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_12       │ (None, 19, 19, 728)    │        536,536 │ activation_13[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_17    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_12[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_14             │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_13       │ (None, 19, 19, 728)    │        536,536 │ activation_14[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_18    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_13[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_15             │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_14       │ (None, 19, 19, 728)    │        536,536 │ activation_15[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_19    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_14[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_5 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│                           │                        │                │ add_4[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_16             │ (None, 19, 19, 728)    │              0 │ add_5[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_15       │ (None, 19, 19, 728)    │        536,536 │ activation_16[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_20    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_15[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_17             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_16       │ (None, 19, 19, 728)    │        536,536 │ activation_17[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_21    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_16[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_18             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_17       │ (None, 19, 19, 728)    │        536,536 │ activation_18[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_22    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_17[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_6 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│                           │                        │                │ add_5[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_19             │ (None, 19, 19, 728)    │              0 │ add_6[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_18       │ (None, 19, 19, 728)    │        536,536 │ activation_19[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_23    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_18[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_20             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_19       │ (None, 19, 19, 728)    │        536,536 │ activation_20[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_24    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_19[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_21             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_20       │ (None, 19, 19, 728)    │        536,536 │ activation_21[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_25    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_20[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_7 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│                           │                        │                │ add_6[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_22             │ (None, 19, 19, 728)    │              0 │ add_7[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_21       │ (None, 19, 19, 728)    │        536,536 │ activation_22[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_26    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_21[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_23             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_22       │ (None, 19, 19, 728)    │        536,536 │ activation_23[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_27    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_22[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_24             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_23       │ (None, 19, 19, 728)    │        536,536 │ activation_24[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_28    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_23[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_8 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│                           │                        │                │ add_7[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_25             │ (None, 19, 19, 728)    │              0 │ add_8[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_24       │ (None, 19, 19, 728)    │        536,536 │ activation_25[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_29    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_24[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_26             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_25       │ (None, 19, 19, 728)    │        536,536 │ activation_26[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_30    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_25[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_27             │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_26       │ (None, 19, 19, 728)    │        536,536 │ activation_27[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_31    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_26[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_9 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│                           │                        │                │ add_8[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_28             │ (None, 19, 19, 728)    │              0 │ add_9[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_27       │ (None, 19, 19, 728)    │        536,536 │ activation_28[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_32    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_27[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_29             │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_28       │ (None, 19, 19, 728)    │        536,536 │ activation_29[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_33    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_28[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_30             │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_29       │ (None, 19, 19, 728)    │        536,536 │ activation_30[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_34    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_29[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_10 (Add)              │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│                           │                        │                │ add_9[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_31             │ (None, 19, 19, 728)    │              0 │ add_10[0][0]           │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_30       │ (None, 19, 19, 728)    │        536,536 │ activation_31[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_36    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_30[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_32             │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_31       │ (None, 19, 19, 1024)   │        752,024 │ activation_32[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_37    │ (None, 19, 19, 1024)   │          4,096 │ separable_conv2d_31[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_5 (Conv2D)         │ (None, 10, 10, 1024)   │        745,472 │ add_10[0][0]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_3           │ (None, 10, 10, 1024)   │              0 │ batch_normalization_3… │\n│ (MaxPooling2D)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_35    │ (None, 10, 10, 1024)   │          4,096 │ conv2d_5[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_11 (Add)              │ (None, 10, 10, 1024)   │              0 │ max_pooling2d_3[0][0], │\n│                           │                        │                │ batch_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_32       │ (None, 10, 10, 1536)   │      1,582,080 │ add_11[0][0]           │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_38    │ (None, 10, 10, 1536)   │          6,144 │ separable_conv2d_32[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_33             │ (None, 10, 10, 1536)   │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_33       │ (None, 10, 10, 2048)   │      3,159,552 │ activation_33[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_39    │ (None, 10, 10, 2048)   │          8,192 │ separable_conv2d_33[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_34             │ (None, 10, 10, 2048)   │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d  │ (None, 2048)           │              0 │ activation_34[0][0]    │\n│ (GlobalAveragePooling2D)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (Dense)             │ (None, 4)              │          8,196 │ global_average_poolin… │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n Total params: 20,869,676 (79.61 MB)\n Trainable params: 20,815,148 (79.40 MB)\n Non-trainable params: 54,528 (213.00 KB)\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"x = []\nlabel = []\nx_validation = []\nlabel_validation = []\nx_test = []\nlabel_test = []\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T13:12:05.641792Z","iopub.execute_input":"2025-01-31T13:12:05.642162Z","iopub.status.idle":"2025-01-31T13:12:05.645725Z","shell.execute_reply.started":"2025-01-31T13:12:05.642129Z","shell.execute_reply":"2025-01-31T13:12:05.644897Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"csv_file = pd.read_csv(\"/kaggle/input/tea-image-dataset-nlmd-filtered/splited_into_5_fold.csv\")\nprint(csv_file)\n\nfolded = csv_file.groupby(\"fold\")\ntemp_image_name = \"\"\ntemp_image = []\nfor i,j in folded:\n    if i == 4: # testing\n        print(\"fold \"+str(i))\n        cat = j.groupby(\"category\")\n        for k,l in cat:\n            if k == \"Brown_blight\":\n                brown_blight_image_name = l['image_name']\n                brown_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Brown_blight\"\n                \n                for m in brown_blight_image_name:\n                    brown_blight_image = cv2.imread(brown_blight_link + '/'+\"nlmd_\"+m)\n                    brown_blight_image = cv2.resize( brown_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = brown_blight_image\n                    \"\"\"\n                    x_test.append(brown_blight_image)\n                    label_test.append([0])\n                print(len(x_test),\" \",len(label_test))\n                    \n            if k == \"Grey_blight\":\n                grey_blight_image_name = l['image_name']    \n                grey_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Grey_blight\"\n\n                for m in grey_blight_image_name:\n                    grey_blight_image = cv2.imread(grey_blight_link + '/'+\"nlmd_\"+m)\n                    grey_blight_image = cv2.resize( grey_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = grey_blight_image\n                    \"\"\"\n                    x_test.append(grey_blight_image)\n                    label_test.append([1])\n                print(len(x_test),\" \",len(label_test))\n                    \n            if k == \"Healthy\":\n                healthy_image_name = l['image_name']    \n                healthy_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Healthy\"\n\n                for m in healthy_image_name:\n                    healthy_image = cv2.imread(healthy_link + '/'+\"nlmd_\"+m)\n                    healthy_image = cv2.resize( healthy_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = healthy_image\n                    \"\"\"\n                    x_test.append( healthy_image)\n                    label_test.append([2])\n                print(len(x_test),\" \",len(label_test))\n\n            if k == \"Red_rust\":\n                red_rust_image_name = l['image_name']\n                red_rust_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Red_rust\"\n\n                for m in red_rust_image_name:\n                    red_rust_image = cv2.imread(red_rust_link+ '/' + \"nlmd_\"+m)\n                    red_rust_image = cv2.resize(red_rust_image, (img_size, img_size))\n                    x_test.append(red_rust_image)\n                    label_test.append([3])\n                print(len(x_test),\" \", len(label_test))\n            \n    \n    elif i == 0: # validation\n        print(\"fold \"+str(i))\n        cat = j.groupby(\"category\")\n        for k,l in cat:\n            if k == \"Brown_blight\":\n                brown_blight_image_name = l['image_name']\n                brown_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Brown_blight\"\n                \n                for m in brown_blight_image_name:\n                    brown_blight_image = cv2.imread(brown_blight_link + '/'+\"nlmd_\"+m)\n                    brown_blight_image = cv2.resize(brown_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = brown_blight_image\n                    \"\"\"\n                    x_validation.append(brown_blight_image)\n                    label_validation.append([0])\n                print(len(x_validation),\" \",len(label_validation))\n                    \n            if k == \"Grey_blight\":\n                grey_blight_image_name = l['image_name']    \n                grey_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Grey_blight\"\n\n                for m in grey_blight_image_name:\n                    grey_blight_image = cv2.imread(grey_blight_link + '/'+\"nlmd_\"+m)\n                    grey_blight_image = cv2.resize( grey_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = grey_blight_image\n                    \"\"\"\n                    x_validation.append(grey_blight_image)\n                    label_validation.append([1])\n                print(len(x_validation),\" \",len(label_validation))\n                    \n            if k == \"Healthy\":\n                healthy_image_name = l['image_name']    \n                healthy_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Healthy\"\n\n                for m in healthy_image_name:\n                    healthy_image = cv2.imread(healthy_link + '/'+\"nlmd_\"+m)\n                    healthy_image =  cv2.resize(healthy_image , ( img_size , img_size ))\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = healthy_image\n                    x_validation.append( healthy_image)\n                    label_validation.append([2])\n                print(len(x_validation),\" \",len(label_validation))\n                \n            if k == \"Red_rust\":\n                red_rust_image_name = l['image_name']\n                red_rust_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Red_rust\"\n\n                for m in red_rust_image_name:\n                    red_rust_image = cv2.imread(red_rust_link+ '/' + \"nlmd_\"+m)\n                    red_rust_image = cv2.resize(red_rust_image, (img_size, img_size))\n                    x_validation.append(red_rust_image)\n                    label_validation.append([3])\n                print(len(x_validation),\" \", len(label_validation))\n            \n\n    else: # training\n        print(\"fold \"+str(i))\n        cat = j.groupby(\"category\")\n        for k,l in cat:\n            if k == \"Brown_blight\":\n                brown_blight_image_name = l['image_name']\n                brown_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Brown_blight\"\n                \n                for m in brown_blight_image_name:\n                    brown_blight_image = cv2.imread(brown_blight_link + '/'+\"nlmd_\"+m)\n                    brown_blight_image = cv2.resize(brown_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = brown_blight_image\n                    \"\"\"\n                    x.append(brown_blight_image)\n                    label.append([0])\n                print(len(x),\" \",len(label))\n            if k == \"Grey_blight\":\n                grey_blight_image_name = l['image_name']    \n                grey_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Grey_blight\"\n\n                for m in grey_blight_image_name:\n                    grey_blight_image = cv2.imread(grey_blight_link + '/'+\"nlmd_\"+m)\n                    grey_blight_image = cv2.resize( grey_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = grey_blight_image\n                    \"\"\"\n                    x.append(grey_blight_image)\n                    label.append([1])\n                print(len(x),\" \",len(label))\n                    \n            if k == \"Healthy\":\n                healthy_image_name = l['image_name']    \n                healthy_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Healthy\"\n\n                for m in healthy_image_name:\n                    healthy_image = cv2.imread(healthy_link + '/'+\"nlmd_\"+m)\n                    healthy_image =  cv2.resize(healthy_image , ( img_size , img_size ))\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = healthy_image\n                    x.append( healthy_image)\n                    label.append([2])\n                print(len(x),\" \",len(label))\n                \n            if k == \"Red_rust\":\n                red_rust_image_name = l['image_name']\n                red_rust_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Red_rust\"\n\n                for m in red_rust_image_name:\n                    red_rust_image = cv2.imread(red_rust_link+ '/' + \"nlmd_\"+m)\n                    red_rust_image = cv2.resize(red_rust_image, (img_size, img_size))\n                    x.append(red_rust_image)\n                    label.append([3])\n                print(len(x),\" \", len(label))\n            \n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T13:12:05.647335Z","iopub.execute_input":"2025-01-31T13:12:05.647543Z","iopub.status.idle":"2025-01-31T13:15:48.100438Z","shell.execute_reply.started":"2025-01-31T13:12:05.647525Z","shell.execute_reply":"2025-01-31T13:15:48.099528Z"}},"outputs":[{"name":"stdout","text":"                 image_name  fold      category\n0      Training_img_280.jpg     0  Brown_blight\n1      Training_img_662.jpg     0  Brown_blight\n2      Training_img_651.jpg     0  Brown_blight\n3      Training_img_809.jpg     0  Brown_blight\n4      Training_img_546.jpg     0  Brown_blight\n...                     ...   ...           ...\n3229  Training_img_2989.jpg     4      Red_rust\n3230  Training_img_2880.jpg     4      Red_rust\n3231  Training_img_2693.jpg     4      Red_rust\n3232  Training_img_2997.jpg     4      Red_rust\n3233  Training_img_2993.jpg     4      Red_rust\n\n[3234 rows x 3 columns]\nfold 0\n159   159\n329   329\n491   491\n649   649\nfold 1\n159   159\n328   328\n490   490\n648   648\nfold 2\n806   806\n975   975\n1137   1137\n1294   1294\nfold 3\n1452   1452\n1621   1621\n1783   1783\n1940   1940\nfold 4\n158   158\n327   327\n488   488\n645   645\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"print(len(x),\" \",len(label))\nprint(len(x_validation),\" \",len(label_validation))\nprint(len(x_test),\" \",len(label_test))\nprint(\"Hello world.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T13:15:48.101997Z","iopub.execute_input":"2025-01-31T13:15:48.102293Z","iopub.status.idle":"2025-01-31T13:15:48.108199Z","shell.execute_reply.started":"2025-01-31T13:15:48.102268Z","shell.execute_reply":"2025-01-31T13:15:48.107551Z"}},"outputs":[{"name":"stdout","text":"1940   1940\n649   649\n645   645\nHello world.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"x = np.asarray(x)\nx_validation = np.asarray(x_validation)\nx_test = np.asarray(x_test)\n\nprint(len(x),\" \", len(x_validation),\" \", len(x_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T13:15:48.108925Z","iopub.execute_input":"2025-01-31T13:15:48.109227Z","iopub.status.idle":"2025-01-31T13:15:48.351874Z","shell.execute_reply.started":"2025-01-31T13:15:48.109197Z","shell.execute_reply":"2025-01-31T13:15:48.351140Z"}},"outputs":[{"name":"stdout","text":"1940   649   645\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical \n\nlabel = np.array(label)\nlabel = to_categorical(label , 4 )\nprint(len(label))\n\n\n\nlabel = np.array(label)\nlabel_validation = to_categorical(label_validation , 4 )\nprint(len(label_validation))\n\nlabel = np.array(label)\nlabel_test = to_categorical(label_test , 4 )\nprint(len(label_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T13:15:48.352666Z","iopub.execute_input":"2025-01-31T13:15:48.352895Z","iopub.status.idle":"2025-01-31T13:15:48.363266Z","shell.execute_reply.started":"2025-01-31T13:15:48.352876Z","shell.execute_reply":"2025-01-31T13:15:48.362541Z"}},"outputs":[{"name":"stdout","text":"1940\n649\n645\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"print(label[491])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T13:15:48.363950Z","iopub.execute_input":"2025-01-31T13:15:48.364266Z","iopub.status.idle":"2025-01-31T13:15:48.379112Z","shell.execute_reply.started":"2025-01-31T13:15:48.364238Z","shell.execute_reply":"2025-01-31T13:15:48.378417Z"}},"outputs":[{"name":"stdout","text":"[0. 0. 0. 1.]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"early_stop  = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience= 90 , verbose=0, mode='max')\n#check_point = tf.keras.callbacks.ModelCheckpoint('/kaggle/working/xception_tea_leaves_nlmd_filtered.h5', monitor='val_acc', save_best_only=True, mode='max')\ncheck_point = tf.keras.callbacks.ModelCheckpoint('/kaggle/working/xception_tea_leaves_nlmd_filtered_4_0.keras', monitor='val_accuracy', save_best_only=True, mode='max')\n\nhistory = model.fit(x , label , validation_data = (x_validation , label_validation ), epochs = 100 , callbacks=[early_stop, check_point])\n    \n\nprint(\"skip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T13:15:48.379790Z","iopub.execute_input":"2025-01-31T13:15:48.380109Z","iopub.status.idle":"2025-01-31T14:45:50.352627Z","shell.execute_reply.started":"2025-01-31T13:15:48.380077Z","shell.execute_reply":"2025-01-31T14:45:50.351727Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m175s\u001b[0m 2s/step - accuracy: 0.5776 - loss: 1.0350 - val_accuracy: 0.2619 - val_loss: 1.3858\nEpoch 2/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 882ms/step - accuracy: 0.8065 - loss: 0.4846 - val_accuracy: 0.2250 - val_loss: 1.3921\nEpoch 3/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 851ms/step - accuracy: 0.8759 - loss: 0.3205 - val_accuracy: 0.2496 - val_loss: 1.3926\nEpoch 4/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 861ms/step - accuracy: 0.8901 - loss: 0.2842 - val_accuracy: 0.2558 - val_loss: 1.4002\nEpoch 5/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 882ms/step - accuracy: 0.9123 - loss: 0.2421 - val_accuracy: 0.3667 - val_loss: 1.5220\nEpoch 6/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 862ms/step - accuracy: 0.9203 - loss: 0.2246 - val_accuracy: 0.2619 - val_loss: 1.6181\nEpoch 7/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 862ms/step - accuracy: 0.9262 - loss: 0.1927 - val_accuracy: 0.3143 - val_loss: 1.7939\nEpoch 8/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 885ms/step - accuracy: 0.9468 - loss: 0.1629 - val_accuracy: 0.9230 - val_loss: 0.3444\nEpoch 9/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 860ms/step - accuracy: 0.9195 - loss: 0.1981 - val_accuracy: 0.9137 - val_loss: 0.2443\nEpoch 10/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 864ms/step - accuracy: 0.9507 - loss: 0.1292 - val_accuracy: 0.7180 - val_loss: 2.3511\nEpoch 11/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 864ms/step - accuracy: 0.9438 - loss: 0.1709 - val_accuracy: 0.8398 - val_loss: 0.5725\nEpoch 12/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 865ms/step - accuracy: 0.9660 - loss: 0.1041 - val_accuracy: 0.8659 - val_loss: 0.4116\nEpoch 13/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 864ms/step - accuracy: 0.9640 - loss: 0.1297 - val_accuracy: 0.7458 - val_loss: 1.8198\nEpoch 14/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 864ms/step - accuracy: 0.9496 - loss: 0.1649 - val_accuracy: 0.4530 - val_loss: 2.8821\nEpoch 15/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 865ms/step - accuracy: 0.9675 - loss: 0.0922 - val_accuracy: 0.7643 - val_loss: 0.7093\nEpoch 16/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 867ms/step - accuracy: 0.9800 - loss: 0.0607 - val_accuracy: 0.7997 - val_loss: 1.1412\nEpoch 17/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 867ms/step - accuracy: 0.9699 - loss: 0.0767 - val_accuracy: 0.7704 - val_loss: 1.5166\nEpoch 18/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 865ms/step - accuracy: 0.9644 - loss: 0.0989 - val_accuracy: 0.7766 - val_loss: 2.0455\nEpoch 19/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 865ms/step - accuracy: 0.9779 - loss: 0.0591 - val_accuracy: 0.7134 - val_loss: 1.3996\nEpoch 20/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 865ms/step - accuracy: 0.9760 - loss: 0.0664 - val_accuracy: 0.4052 - val_loss: 9.1596\nEpoch 21/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 865ms/step - accuracy: 0.9711 - loss: 0.0691 - val_accuracy: 0.4669 - val_loss: 4.3437\nEpoch 22/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 867ms/step - accuracy: 0.9848 - loss: 0.0484 - val_accuracy: 0.7473 - val_loss: 1.2554\nEpoch 23/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 866ms/step - accuracy: 0.9812 - loss: 0.0527 - val_accuracy: 0.7951 - val_loss: 0.8700\nEpoch 24/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 866ms/step - accuracy: 0.9824 - loss: 0.0490 - val_accuracy: 0.7827 - val_loss: 0.8950\nEpoch 25/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 866ms/step - accuracy: 0.9918 - loss: 0.0285 - val_accuracy: 0.8844 - val_loss: 0.5171\nEpoch 26/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 865ms/step - accuracy: 0.9983 - loss: 0.0122 - val_accuracy: 0.9153 - val_loss: 0.2745\nEpoch 27/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 863ms/step - accuracy: 0.9826 - loss: 0.0439 - val_accuracy: 0.8043 - val_loss: 1.4137\nEpoch 28/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 860ms/step - accuracy: 0.9758 - loss: 0.0733 - val_accuracy: 0.7350 - val_loss: 1.5732\nEpoch 29/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 859ms/step - accuracy: 0.9785 - loss: 0.0529 - val_accuracy: 0.8582 - val_loss: 0.7945\nEpoch 30/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 857ms/step - accuracy: 0.9904 - loss: 0.0326 - val_accuracy: 0.6194 - val_loss: 1.6793\nEpoch 31/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 861ms/step - accuracy: 0.9907 - loss: 0.0293 - val_accuracy: 0.8197 - val_loss: 0.7678\nEpoch 32/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 863ms/step - accuracy: 0.9872 - loss: 0.0320 - val_accuracy: 0.5932 - val_loss: 2.1562\nEpoch 33/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 865ms/step - accuracy: 0.9809 - loss: 0.0563 - val_accuracy: 0.6703 - val_loss: 2.1714\nEpoch 34/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 865ms/step - accuracy: 0.9844 - loss: 0.0394 - val_accuracy: 0.7288 - val_loss: 1.3207\nEpoch 35/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 865ms/step - accuracy: 0.9855 - loss: 0.0473 - val_accuracy: 0.9214 - val_loss: 0.3162\nEpoch 36/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 866ms/step - accuracy: 0.9880 - loss: 0.0344 - val_accuracy: 0.7858 - val_loss: 1.3425\nEpoch 37/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 866ms/step - accuracy: 0.9877 - loss: 0.0415 - val_accuracy: 0.7242 - val_loss: 1.3860\nEpoch 38/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 890ms/step - accuracy: 0.9947 - loss: 0.0122 - val_accuracy: 0.9260 - val_loss: 0.2366\nEpoch 39/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 864ms/step - accuracy: 0.9961 - loss: 0.0149 - val_accuracy: 0.8675 - val_loss: 0.7455\nEpoch 40/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 890ms/step - accuracy: 0.9969 - loss: 0.0089 - val_accuracy: 0.9538 - val_loss: 0.2040\nEpoch 41/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 890ms/step - accuracy: 0.9994 - loss: 0.0058 - val_accuracy: 0.9599 - val_loss: 0.1468\nEpoch 42/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 867ms/step - accuracy: 0.9864 - loss: 0.0366 - val_accuracy: 0.9461 - val_loss: 0.2329\nEpoch 43/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 868ms/step - accuracy: 0.9954 - loss: 0.0259 - val_accuracy: 0.8320 - val_loss: 0.6095\nEpoch 44/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 865ms/step - accuracy: 0.9977 - loss: 0.0085 - val_accuracy: 0.9153 - val_loss: 0.2759\nEpoch 45/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 887ms/step - accuracy: 0.9955 - loss: 0.0175 - val_accuracy: 0.9615 - val_loss: 0.1389\nEpoch 46/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 862ms/step - accuracy: 0.9964 - loss: 0.0107 - val_accuracy: 0.8552 - val_loss: 0.8302\nEpoch 47/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 866ms/step - accuracy: 0.9929 - loss: 0.0172 - val_accuracy: 0.8367 - val_loss: 0.6401\nEpoch 48/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 865ms/step - accuracy: 0.9951 - loss: 0.0218 - val_accuracy: 0.7565 - val_loss: 2.9448\nEpoch 49/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 866ms/step - accuracy: 0.9929 - loss: 0.0284 - val_accuracy: 0.8968 - val_loss: 0.3761\nEpoch 50/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 867ms/step - accuracy: 0.9848 - loss: 0.0355 - val_accuracy: 0.7042 - val_loss: 3.3806\nEpoch 51/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 866ms/step - accuracy: 0.9893 - loss: 0.0418 - val_accuracy: 0.7550 - val_loss: 1.7658\nEpoch 52/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 866ms/step - accuracy: 0.9906 - loss: 0.0317 - val_accuracy: 0.9106 - val_loss: 0.3026\nEpoch 53/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 865ms/step - accuracy: 0.9807 - loss: 0.0515 - val_accuracy: 0.5840 - val_loss: 2.0128\nEpoch 54/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 864ms/step - accuracy: 0.9798 - loss: 0.0608 - val_accuracy: 0.5901 - val_loss: 6.4466\nEpoch 55/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 864ms/step - accuracy: 0.9881 - loss: 0.0254 - val_accuracy: 0.8937 - val_loss: 0.4391\nEpoch 56/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 865ms/step - accuracy: 0.9928 - loss: 0.0153 - val_accuracy: 0.8136 - val_loss: 1.3172\nEpoch 57/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 866ms/step - accuracy: 0.9915 - loss: 0.0236 - val_accuracy: 0.8798 - val_loss: 0.6639\nEpoch 58/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 864ms/step - accuracy: 0.9869 - loss: 0.0492 - val_accuracy: 0.8351 - val_loss: 1.1138\nEpoch 59/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 865ms/step - accuracy: 0.9867 - loss: 0.0299 - val_accuracy: 0.9522 - val_loss: 0.2209\nEpoch 60/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 864ms/step - accuracy: 0.9801 - loss: 0.0506 - val_accuracy: 0.7750 - val_loss: 2.0890\nEpoch 61/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 864ms/step - accuracy: 0.9927 - loss: 0.0193 - val_accuracy: 0.7997 - val_loss: 1.0031\nEpoch 62/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 863ms/step - accuracy: 0.9980 - loss: 0.0057 - val_accuracy: 0.8613 - val_loss: 0.9202\nEpoch 63/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 864ms/step - accuracy: 0.9981 - loss: 0.0076 - val_accuracy: 0.8875 - val_loss: 0.5031\nEpoch 64/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 864ms/step - accuracy: 0.9924 - loss: 0.0224 - val_accuracy: 0.9029 - val_loss: 0.2987\nEpoch 65/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 865ms/step - accuracy: 0.9986 - loss: 0.0048 - val_accuracy: 0.7874 - val_loss: 1.0417\nEpoch 66/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 887ms/step - accuracy: 0.9980 - loss: 0.0068 - val_accuracy: 0.9738 - val_loss: 0.1299\nEpoch 67/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 862ms/step - accuracy: 0.9992 - loss: 0.0032 - val_accuracy: 0.8952 - val_loss: 0.4582\nEpoch 68/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 866ms/step - accuracy: 0.9987 - loss: 0.0058 - val_accuracy: 0.8613 - val_loss: 0.5707\nEpoch 69/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 867ms/step - accuracy: 0.9958 - loss: 0.0153 - val_accuracy: 0.9707 - val_loss: 0.1565\nEpoch 70/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 866ms/step - accuracy: 0.9989 - loss: 0.0049 - val_accuracy: 0.9599 - val_loss: 0.1906\nEpoch 71/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 866ms/step - accuracy: 0.9985 - loss: 0.0063 - val_accuracy: 0.7935 - val_loss: 1.4482\nEpoch 72/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 866ms/step - accuracy: 0.9950 - loss: 0.0200 - val_accuracy: 0.7488 - val_loss: 1.2817\nEpoch 73/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 864ms/step - accuracy: 0.9669 - loss: 0.0842 - val_accuracy: 0.8182 - val_loss: 0.9614\nEpoch 74/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 866ms/step - accuracy: 0.9758 - loss: 0.0618 - val_accuracy: 0.6502 - val_loss: 3.9221\nEpoch 75/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 865ms/step - accuracy: 0.9902 - loss: 0.0307 - val_accuracy: 0.7704 - val_loss: 1.3583\nEpoch 76/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 865ms/step - accuracy: 0.9965 - loss: 0.0127 - val_accuracy: 0.9322 - val_loss: 0.3339\nEpoch 77/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 866ms/step - accuracy: 0.9984 - loss: 0.0084 - val_accuracy: 0.9646 - val_loss: 0.1706\nEpoch 78/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 866ms/step - accuracy: 0.9969 - loss: 0.0130 - val_accuracy: 0.9291 - val_loss: 0.2529\nEpoch 79/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 865ms/step - accuracy: 0.9948 - loss: 0.0120 - val_accuracy: 0.9630 - val_loss: 0.1496\nEpoch 80/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 867ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.9353 - val_loss: 0.3171\nEpoch 81/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 866ms/step - accuracy: 0.9982 - loss: 0.0049 - val_accuracy: 0.8814 - val_loss: 0.4133\nEpoch 82/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 866ms/step - accuracy: 0.9962 - loss: 0.0100 - val_accuracy: 0.7519 - val_loss: 0.9740\nEpoch 83/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 866ms/step - accuracy: 0.9951 - loss: 0.0181 - val_accuracy: 0.9414 - val_loss: 0.3075\nEpoch 84/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 867ms/step - accuracy: 0.9954 - loss: 0.0160 - val_accuracy: 0.8305 - val_loss: 0.6674\nEpoch 85/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 867ms/step - accuracy: 0.9904 - loss: 0.0287 - val_accuracy: 0.4006 - val_loss: 5.3016\nEpoch 86/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 866ms/step - accuracy: 0.9803 - loss: 0.0687 - val_accuracy: 0.7658 - val_loss: 1.4731\nEpoch 87/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 867ms/step - accuracy: 0.9838 - loss: 0.0444 - val_accuracy: 0.7535 - val_loss: 2.8262\nEpoch 88/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 864ms/step - accuracy: 0.9906 - loss: 0.0204 - val_accuracy: 0.4237 - val_loss: 5.5783\nEpoch 89/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 863ms/step - accuracy: 0.9897 - loss: 0.0288 - val_accuracy: 0.8505 - val_loss: 0.5744\nEpoch 90/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 863ms/step - accuracy: 0.9972 - loss: 0.0047 - val_accuracy: 0.8444 - val_loss: 0.6497\nEpoch 91/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 863ms/step - accuracy: 0.9990 - loss: 0.0067 - val_accuracy: 0.9630 - val_loss: 0.1857\nEpoch 92/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 863ms/step - accuracy: 0.9999 - loss: 0.0024 - val_accuracy: 0.9569 - val_loss: 0.1538\nEpoch 93/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 863ms/step - accuracy: 0.9955 - loss: 0.0157 - val_accuracy: 0.9199 - val_loss: 0.2926\nEpoch 94/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 862ms/step - accuracy: 0.9970 - loss: 0.0069 - val_accuracy: 0.9260 - val_loss: 0.2018\nEpoch 95/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 861ms/step - accuracy: 0.9824 - loss: 0.0484 - val_accuracy: 0.9260 - val_loss: 0.3292\nEpoch 96/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 863ms/step - accuracy: 0.9880 - loss: 0.0447 - val_accuracy: 0.8829 - val_loss: 0.6215\nEpoch 97/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 863ms/step - accuracy: 0.9932 - loss: 0.0207 - val_accuracy: 0.9291 - val_loss: 0.3029\nEpoch 98/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 864ms/step - accuracy: 0.9982 - loss: 0.0064 - val_accuracy: 0.8074 - val_loss: 1.4355\nEpoch 99/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 863ms/step - accuracy: 0.9966 - loss: 0.0117 - val_accuracy: 0.9307 - val_loss: 0.2892\nEpoch 100/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 865ms/step - accuracy: 0.9981 - loss: 0.0051 - val_accuracy: 0.5932 - val_loss: 3.8170\nskip\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"a = 5\nwhile(True):\n    a = 10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T14:45:50.353434Z","iopub.execute_input":"2025-01-31T14:45:50.353838Z"}},"outputs":[],"execution_count":null}]}