{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10602688,"sourceType":"datasetVersion","datasetId":6527737}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow import keras\nfrom keras.models import Model\nfrom keras import layers\nfrom keras.layers import Dense, Input, BatchNormalization, Activation\nfrom keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n#from keras.applications.imagenet_utils import _obtain_input_shape\n#from keras.utils.data_utils import get_file\nfrom sklearn.model_selection import KFold\nfrom keras.datasets import mnist\nfrom PIL import Image\n# for creating a one hot vector for labels\n#from keras.utils import np_utils\nfrom IPython.display import display, Image\n#import the models\nfrom keras import Model\n#add layers\nfrom keras import layers\n#add optimizer\nfrom keras import optimizers\n#add loss function \nfrom keras import losses\nimport random\n\nimport keras\nimport numpy as np\nimport pandas as pd \nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport tensorflow.keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:42:14.557549Z","iopub.execute_input":"2025-01-31T03:42:14.557861Z","iopub.status.idle":"2025-01-31T03:42:27.252078Z","shell.execute_reply.started":"2025-01-31T03:42:14.557829Z","shell.execute_reply":"2025-01-31T03:42:27.251175Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from tensorflow import keras\nfrom keras.models import Model\nfrom keras.layers import Dense, Input, BatchNormalization, Activation\nfrom keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom IPython.core.display import display, HTML\nimport sys\n\n# Adjust notebook display width\ndisplay(HTML(\"<style>.container { width:90% !important; }</style>\"))\n\n\nimg_size = 299\ndef Xception():\n\n\t# Determine proper input shape\n\tinput_shape = (img_size, img_size, 3 )#_obtain_input_shape(None, default_size=299, min_size=71, data_format='channels_last', include_top=False)\n\n\timg_input = Input(shape=input_shape)\n\n\t# Block 1\n\tx = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False)(img_input)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = Conv2D(64, (3, 3), use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\n\tresidual = Conv2D(128, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n\tresidual = BatchNormalization()(residual)\n\n\t# Block 2\n\tx = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\n\t# Block 2 Pool\n\tx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\tx = layers.add([x, residual])\n\n\tresidual = Conv2D(256, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n\tresidual = BatchNormalization()(residual)\n\n\t# Block 3\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\n\t# Block 3 Pool\n\tx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\tx = layers.add([x, residual])\n\n\tresidual = Conv2D(728, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n\tresidual = BatchNormalization()(residual)\n\n\t# Block 4\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\n\tx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\tx = layers.add([x, residual])\n\n\t# Block 5 - 12\n\tfor i in range(8):\n\t\tresidual = x\n\n\t\tx = Activation('relu')(x)\n\t\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\t\tx = BatchNormalization()(x)\n\t\tx = Activation('relu')(x)\n\t\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\t\tx = BatchNormalization()(x)\n\t\tx = Activation('relu')(x)\n\t\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\t\tx = BatchNormalization()(x)\n\n\t\tx = layers.add([x, residual])\n\n\tresidual = Conv2D(1024, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n\tresidual = BatchNormalization()(residual)\n\n\t# Block 13\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(1024, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\n\t# Block 13 Pool\n\tx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\tx = layers.add([x, residual])\n\n\t# Block 14\n\tx = SeparableConv2D(1536, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\n\t# Block 14 part 2\n\tx = SeparableConv2D(2048, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\n\t# Fully Connected Layer\n\tx = GlobalAveragePooling2D()(x)\n\tx = Dense( 4 , activation='softmax')(x)\n\n\tinputs = img_input\n\n\t# Create model\n\tmodel = Model(inputs, x, name='xception')\n\n\t# Download and cache the Xception weights file\n\n\n\treturn model\n\nmodel = Xception()\n\nmodel.compile(\n    optimizer='Adam',\n    loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n    metrics=[\"accuracy\"],\n)\n\n# Print the model summary\nmodel.summary(print_fn=lambda x: sys.stdout.write(x + '\\n'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:42:27.252952Z","iopub.execute_input":"2025-01-31T03:42:27.253357Z","iopub.status.idle":"2025-01-31T03:42:30.289150Z","shell.execute_reply.started":"2025-01-31T03:42:27.253336Z","shell.execute_reply":"2025-01-31T03:42:30.288246Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>.container { width:90% !important; }</style>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"name":"stdout","text":"Model: \"xception\"\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃ Layer (type)              ┃ Output Shape           ┃        Param # ┃ Connected to           ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (InputLayer)  │ (None, 299, 299, 3)    │              0 │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d (Conv2D)           │ (None, 149, 149, 32)   │            864 │ input_layer[0][0]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization       │ (None, 149, 149, 32)   │            128 │ conv2d[0][0]           │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation (Activation)   │ (None, 149, 149, 32)   │              0 │ batch_normalization[0… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_1 (Conv2D)         │ (None, 147, 147, 64)   │         18,432 │ activation[0][0]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_1     │ (None, 147, 147, 64)   │            256 │ conv2d_1[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_1 (Activation) │ (None, 147, 147, 64)   │              0 │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d          │ (None, 147, 147, 128)  │          8,768 │ activation_1[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_3     │ (None, 147, 147, 128)  │            512 │ separable_conv2d[0][0] │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_2 (Activation) │ (None, 147, 147, 128)  │              0 │ batch_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_1        │ (None, 147, 147, 128)  │         17,536 │ activation_2[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_4     │ (None, 147, 147, 128)  │            512 │ separable_conv2d_1[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_2 (Conv2D)         │ (None, 74, 74, 128)    │          8,192 │ activation_1[0][0]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d             │ (None, 74, 74, 128)    │              0 │ batch_normalization_4… │\n│ (MaxPooling2D)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_2     │ (None, 74, 74, 128)    │            512 │ conv2d_2[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add (Add)                 │ (None, 74, 74, 128)    │              0 │ max_pooling2d[0][0],   │\n│                           │                        │                │ batch_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_3 (Activation) │ (None, 74, 74, 128)    │              0 │ add[0][0]              │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_2        │ (None, 74, 74, 256)    │         33,920 │ activation_3[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_6     │ (None, 74, 74, 256)    │          1,024 │ separable_conv2d_2[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_4 (Activation) │ (None, 74, 74, 256)    │              0 │ batch_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_3        │ (None, 74, 74, 256)    │         67,840 │ activation_4[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_7     │ (None, 74, 74, 256)    │          1,024 │ separable_conv2d_3[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_3 (Conv2D)         │ (None, 37, 37, 256)    │         32,768 │ add[0][0]              │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_1           │ (None, 37, 37, 256)    │              0 │ batch_normalization_7… │\n│ (MaxPooling2D)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_5     │ (None, 37, 37, 256)    │          1,024 │ conv2d_3[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_1 (Add)               │ (None, 37, 37, 256)    │              0 │ max_pooling2d_1[0][0], │\n│                           │                        │                │ batch_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_5 (Activation) │ (None, 37, 37, 256)    │              0 │ add_1[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_4        │ (None, 37, 37, 728)    │        188,672 │ activation_5[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_9     │ (None, 37, 37, 728)    │          2,912 │ separable_conv2d_4[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_6 (Activation) │ (None, 37, 37, 728)    │              0 │ batch_normalization_9… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_5        │ (None, 37, 37, 728)    │        536,536 │ activation_6[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_10    │ (None, 37, 37, 728)    │          2,912 │ separable_conv2d_5[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_4 (Conv2D)         │ (None, 19, 19, 728)    │        186,368 │ add_1[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_2           │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (MaxPooling2D)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_8     │ (None, 19, 19, 728)    │          2,912 │ conv2d_4[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_2 (Add)               │ (None, 19, 19, 728)    │              0 │ max_pooling2d_2[0][0], │\n│                           │                        │                │ batch_normalization_8… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_7 (Activation) │ (None, 19, 19, 728)    │              0 │ add_2[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_6        │ (None, 19, 19, 728)    │        536,536 │ activation_7[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_11    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_6[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_8 (Activation) │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_7        │ (None, 19, 19, 728)    │        536,536 │ activation_8[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_12    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_7[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_9 (Activation) │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_8        │ (None, 19, 19, 728)    │        536,536 │ activation_9[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_13    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_8[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_3 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│                           │                        │                │ add_2[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_10             │ (None, 19, 19, 728)    │              0 │ add_3[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_9        │ (None, 19, 19, 728)    │        536,536 │ activation_10[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_14    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_9[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_11             │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_10       │ (None, 19, 19, 728)    │        536,536 │ activation_11[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_15    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_10[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_12             │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_11       │ (None, 19, 19, 728)    │        536,536 │ activation_12[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_16    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_11[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_4 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│                           │                        │                │ add_3[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_13             │ (None, 19, 19, 728)    │              0 │ add_4[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_12       │ (None, 19, 19, 728)    │        536,536 │ activation_13[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_17    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_12[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_14             │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_13       │ (None, 19, 19, 728)    │        536,536 │ activation_14[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_18    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_13[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_15             │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_14       │ (None, 19, 19, 728)    │        536,536 │ activation_15[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_19    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_14[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_5 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│                           │                        │                │ add_4[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_16             │ (None, 19, 19, 728)    │              0 │ add_5[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_15       │ (None, 19, 19, 728)    │        536,536 │ activation_16[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_20    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_15[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_17             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_16       │ (None, 19, 19, 728)    │        536,536 │ activation_17[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_21    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_16[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_18             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_17       │ (None, 19, 19, 728)    │        536,536 │ activation_18[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_22    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_17[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_6 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│                           │                        │                │ add_5[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_19             │ (None, 19, 19, 728)    │              0 │ add_6[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_18       │ (None, 19, 19, 728)    │        536,536 │ activation_19[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_23    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_18[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_20             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_19       │ (None, 19, 19, 728)    │        536,536 │ activation_20[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_24    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_19[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_21             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_20       │ (None, 19, 19, 728)    │        536,536 │ activation_21[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_25    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_20[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_7 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│                           │                        │                │ add_6[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_22             │ (None, 19, 19, 728)    │              0 │ add_7[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_21       │ (None, 19, 19, 728)    │        536,536 │ activation_22[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_26    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_21[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_23             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_22       │ (None, 19, 19, 728)    │        536,536 │ activation_23[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_27    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_22[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_24             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_23       │ (None, 19, 19, 728)    │        536,536 │ activation_24[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_28    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_23[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_8 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│                           │                        │                │ add_7[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_25             │ (None, 19, 19, 728)    │              0 │ add_8[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_24       │ (None, 19, 19, 728)    │        536,536 │ activation_25[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_29    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_24[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_26             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_25       │ (None, 19, 19, 728)    │        536,536 │ activation_26[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_30    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_25[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_27             │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_26       │ (None, 19, 19, 728)    │        536,536 │ activation_27[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_31    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_26[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_9 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│                           │                        │                │ add_8[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_28             │ (None, 19, 19, 728)    │              0 │ add_9[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_27       │ (None, 19, 19, 728)    │        536,536 │ activation_28[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_32    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_27[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_29             │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_28       │ (None, 19, 19, 728)    │        536,536 │ activation_29[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_33    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_28[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_30             │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_29       │ (None, 19, 19, 728)    │        536,536 │ activation_30[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_34    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_29[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_10 (Add)              │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│                           │                        │                │ add_9[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_31             │ (None, 19, 19, 728)    │              0 │ add_10[0][0]           │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_30       │ (None, 19, 19, 728)    │        536,536 │ activation_31[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_36    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_30[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_32             │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_31       │ (None, 19, 19, 1024)   │        752,024 │ activation_32[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_37    │ (None, 19, 19, 1024)   │          4,096 │ separable_conv2d_31[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_5 (Conv2D)         │ (None, 10, 10, 1024)   │        745,472 │ add_10[0][0]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_3           │ (None, 10, 10, 1024)   │              0 │ batch_normalization_3… │\n│ (MaxPooling2D)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_35    │ (None, 10, 10, 1024)   │          4,096 │ conv2d_5[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_11 (Add)              │ (None, 10, 10, 1024)   │              0 │ max_pooling2d_3[0][0], │\n│                           │                        │                │ batch_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_32       │ (None, 10, 10, 1536)   │      1,582,080 │ add_11[0][0]           │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_38    │ (None, 10, 10, 1536)   │          6,144 │ separable_conv2d_32[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_33             │ (None, 10, 10, 1536)   │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_33       │ (None, 10, 10, 2048)   │      3,159,552 │ activation_33[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_39    │ (None, 10, 10, 2048)   │          8,192 │ separable_conv2d_33[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_34             │ (None, 10, 10, 2048)   │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d  │ (None, 2048)           │              0 │ activation_34[0][0]    │\n│ (GlobalAveragePooling2D)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (Dense)             │ (None, 4)              │          8,196 │ global_average_poolin… │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n Total params: 20,869,676 (79.61 MB)\n Trainable params: 20,815,148 (79.40 MB)\n Non-trainable params: 54,528 (213.00 KB)\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"x = []\nlabel = []\nx_validation = []\nlabel_validation = []\nx_test = []\nlabel_test = []\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:42:30.289969Z","iopub.execute_input":"2025-01-31T03:42:30.290212Z","iopub.status.idle":"2025-01-31T03:42:30.293925Z","shell.execute_reply.started":"2025-01-31T03:42:30.290190Z","shell.execute_reply":"2025-01-31T03:42:30.293084Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"csv_file = pd.read_csv(\"/kaggle/input/tea-image-dataset-nlmd-filtered/splited_into_5_fold.csv\")\nprint(csv_file)\n\nfolded = csv_file.groupby(\"fold\")\ntemp_image_name = \"\"\ntemp_image = []\nfor i,j in folded:\n    if i == 2: # testing\n        print(\"fold \"+str(i))\n        cat = j.groupby(\"category\")\n        for k,l in cat:\n            if k == \"Brown_blight\":\n                brown_blight_image_name = l['image_name']\n                brown_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Brown_blight\"\n                \n                for m in brown_blight_image_name:\n                    brown_blight_image = cv2.imread(brown_blight_link + '/'+\"nlmd_\"+m)\n                    brown_blight_image = cv2.resize( brown_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = brown_blight_image\n                    \"\"\"\n                    x_test.append(brown_blight_image)\n                    label_test.append([0])\n                print(len(x_test),\" \",len(label_test))\n                    \n            if k == \"Grey_blight\":\n                grey_blight_image_name = l['image_name']    \n                grey_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Grey_blight\"\n\n                for m in grey_blight_image_name:\n                    grey_blight_image = cv2.imread(grey_blight_link + '/'+\"nlmd_\"+m)\n                    grey_blight_image = cv2.resize( grey_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = grey_blight_image\n                    \"\"\"\n                    x_test.append(grey_blight_image)\n                    label_test.append([1])\n                print(len(x_test),\" \",len(label_test))\n                    \n            if k == \"Healthy\":\n                healthy_image_name = l['image_name']    \n                healthy_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Healthy\"\n\n                for m in healthy_image_name:\n                    healthy_image = cv2.imread(healthy_link + '/'+\"nlmd_\"+m)\n                    healthy_image = cv2.resize( healthy_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = healthy_image\n                    \"\"\"\n                    x_test.append( healthy_image)\n                    label_test.append([2])\n                print(len(x_test),\" \",len(label_test))\n\n            if k == \"Red_rust\":\n                red_rust_image_name = l['image_name']\n                red_rust_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Red_rust\"\n\n                for m in red_rust_image_name:\n                    red_rust_image = cv2.imread(red_rust_link+ '/' + \"nlmd_\"+m)\n                    red_rust_image = cv2.resize(red_rust_image, (img_size, img_size))\n                    x_test.append(red_rust_image)\n                    label_test.append([3])\n                print(len(x_test),\" \", len(label_test))\n            \n    \n    elif i == 3: # validation\n        print(\"fold \"+str(i))\n        cat = j.groupby(\"category\")\n        for k,l in cat:\n            if k == \"Brown_blight\":\n                brown_blight_image_name = l['image_name']\n                brown_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Brown_blight\"\n                \n                for m in brown_blight_image_name:\n                    brown_blight_image = cv2.imread(brown_blight_link + '/'+\"nlmd_\"+m)\n                    brown_blight_image = cv2.resize(brown_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = brown_blight_image\n                    \"\"\"\n                    x_validation.append(brown_blight_image)\n                    label_validation.append([0])\n                print(len(x_validation),\" \",len(label_validation))\n                    \n            if k == \"Grey_blight\":\n                grey_blight_image_name = l['image_name']    \n                grey_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Grey_blight\"\n\n                for m in grey_blight_image_name:\n                    grey_blight_image = cv2.imread(grey_blight_link + '/'+\"nlmd_\"+m)\n                    grey_blight_image = cv2.resize( grey_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = grey_blight_image\n                    \"\"\"\n                    x_validation.append(grey_blight_image)\n                    label_validation.append([1])\n                print(len(x_validation),\" \",len(label_validation))\n                    \n            if k == \"Healthy\":\n                healthy_image_name = l['image_name']    \n                healthy_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Healthy\"\n\n                for m in healthy_image_name:\n                    healthy_image = cv2.imread(healthy_link + '/'+\"nlmd_\"+m)\n                    healthy_image =  cv2.resize(healthy_image , ( img_size , img_size ))\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = healthy_image\n                    x_validation.append( healthy_image)\n                    label_validation.append([2])\n                print(len(x_validation),\" \",len(label_validation))\n                \n            if k == \"Red_rust\":\n                red_rust_image_name = l['image_name']\n                red_rust_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Red_rust\"\n\n                for m in red_rust_image_name:\n                    red_rust_image = cv2.imread(red_rust_link+ '/' + \"nlmd_\"+m)\n                    red_rust_image = cv2.resize(red_rust_image, (img_size, img_size))\n                    x_validation.append(red_rust_image)\n                    label_validation.append([3])\n                print(len(x_validation),\" \", len(label_validation))\n            \n\n    else: # training\n        print(\"fold \"+str(i))\n        cat = j.groupby(\"category\")\n        for k,l in cat:\n            if k == \"Brown_blight\":\n                brown_blight_image_name = l['image_name']\n                brown_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Brown_blight\"\n                \n                for m in brown_blight_image_name:\n                    brown_blight_image = cv2.imread(brown_blight_link + '/'+\"nlmd_\"+m)\n                    brown_blight_image = cv2.resize(brown_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = brown_blight_image\n                    \"\"\"\n                    x.append(brown_blight_image)\n                    label.append([0])\n                print(len(x),\" \",len(label))\n            if k == \"Grey_blight\":\n                grey_blight_image_name = l['image_name']    \n                grey_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Grey_blight\"\n\n                for m in grey_blight_image_name:\n                    grey_blight_image = cv2.imread(grey_blight_link + '/'+\"nlmd_\"+m)\n                    grey_blight_image = cv2.resize( grey_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = grey_blight_image\n                    \"\"\"\n                    x.append(grey_blight_image)\n                    label.append([1])\n                print(len(x),\" \",len(label))\n                    \n            if k == \"Healthy\":\n                healthy_image_name = l['image_name']    \n                healthy_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Healthy\"\n\n                for m in healthy_image_name:\n                    healthy_image = cv2.imread(healthy_link + '/'+\"nlmd_\"+m)\n                    healthy_image =  cv2.resize(healthy_image , ( img_size , img_size ))\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = healthy_image\n                    x.append( healthy_image)\n                    label.append([2])\n                print(len(x),\" \",len(label))\n                \n            if k == \"Red_rust\":\n                red_rust_image_name = l['image_name']\n                red_rust_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Red_rust\"\n\n                for m in red_rust_image_name:\n                    red_rust_image = cv2.imread(red_rust_link+ '/' + \"nlmd_\"+m)\n                    red_rust_image = cv2.resize(red_rust_image, (img_size, img_size))\n                    x.append(red_rust_image)\n                    label.append([3])\n                print(len(x),\" \", len(label))\n            \n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:42:30.295377Z","iopub.execute_input":"2025-01-31T03:42:30.295571Z","iopub.status.idle":"2025-01-31T03:46:26.140941Z","shell.execute_reply.started":"2025-01-31T03:42:30.295555Z","shell.execute_reply":"2025-01-31T03:46:26.140132Z"}},"outputs":[{"name":"stdout","text":"                 image_name  fold      category\n0      Training_img_280.jpg     0  Brown_blight\n1      Training_img_662.jpg     0  Brown_blight\n2      Training_img_651.jpg     0  Brown_blight\n3      Training_img_809.jpg     0  Brown_blight\n4      Training_img_546.jpg     0  Brown_blight\n...                     ...   ...           ...\n3229  Training_img_2989.jpg     4      Red_rust\n3230  Training_img_2880.jpg     4      Red_rust\n3231  Training_img_2693.jpg     4      Red_rust\n3232  Training_img_2997.jpg     4      Red_rust\n3233  Training_img_2993.jpg     4      Red_rust\n\n[3234 rows x 3 columns]\nfold 0\n159   159\n329   329\n491   491\n649   649\nfold 1\n808   808\n977   977\n1139   1139\n1297   1297\nfold 2\n158   158\n327   327\n489   489\n646   646\nfold 3\n158   158\n327   327\n489   489\n646   646\nfold 4\n1455   1455\n1624   1624\n1785   1785\n1942   1942\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"print(len(x),\" \",len(label))\nprint(len(x_validation),\" \",len(label_validation))\nprint(len(x_test),\" \",len(label_test))\nprint(\"Hello world.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:46:26.142273Z","iopub.execute_input":"2025-01-31T03:46:26.142517Z","iopub.status.idle":"2025-01-31T03:46:26.149121Z","shell.execute_reply.started":"2025-01-31T03:46:26.142495Z","shell.execute_reply":"2025-01-31T03:46:26.148369Z"}},"outputs":[{"name":"stdout","text":"1942   1942\n646   646\n646   646\nHello world.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"x = np.asarray(x)\nx_validation = np.asarray(x_validation)\nx_test = np.asarray(x_test)\n\nprint(len(x),\" \", len(x_validation),\" \", len(x_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:46:26.150141Z","iopub.execute_input":"2025-01-31T03:46:26.150429Z","iopub.status.idle":"2025-01-31T03:46:26.390393Z","shell.execute_reply.started":"2025-01-31T03:46:26.150400Z","shell.execute_reply":"2025-01-31T03:46:26.389657Z"}},"outputs":[{"name":"stdout","text":"1942   646   646\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical \n\nlabel = np.array(label)\nlabel = to_categorical(label , 4 )\nprint(len(label))\n\n\n\nlabel = np.array(label)\nlabel_validation = to_categorical(label_validation , 4 )\nprint(len(label_validation))\n\nlabel = np.array(label)\nlabel_test = to_categorical(label_test , 4 )\nprint(len(label_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:46:26.391137Z","iopub.execute_input":"2025-01-31T03:46:26.391427Z","iopub.status.idle":"2025-01-31T03:46:26.400620Z","shell.execute_reply.started":"2025-01-31T03:46:26.391406Z","shell.execute_reply":"2025-01-31T03:46:26.399880Z"}},"outputs":[{"name":"stdout","text":"1942\n646\n646\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"print(label[491])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:46:26.401352Z","iopub.execute_input":"2025-01-31T03:46:26.401630Z","iopub.status.idle":"2025-01-31T03:46:26.415664Z","shell.execute_reply.started":"2025-01-31T03:46:26.401604Z","shell.execute_reply":"2025-01-31T03:46:26.415063Z"}},"outputs":[{"name":"stdout","text":"[0. 0. 0. 1.]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"early_stop  = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience= 90 , verbose=0, mode='max')\n#check_point = tf.keras.callbacks.ModelCheckpoint('/kaggle/working/xception_tea_leaves_nlmd_filtered.h5', monitor='val_acc', save_best_only=True, mode='max')\ncheck_point = tf.keras.callbacks.ModelCheckpoint('/kaggle/working/xception_tea_leaves_nlmd_filtered_2_3.keras', monitor='val_accuracy', save_best_only=True, mode='max')\n\nhistory = model.fit(x , label , validation_data = (x_validation , label_validation ), epochs = 100 , callbacks=[early_stop, check_point])\n    \n\nprint(\"skip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T03:46:26.416357Z","iopub.execute_input":"2025-01-31T03:46:26.416543Z","iopub.status.idle":"2025-01-31T05:10:56.931229Z","shell.execute_reply.started":"2025-01-31T03:46:26.416526Z","shell.execute_reply":"2025-01-31T05:10:56.930274Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 2s/step - accuracy: 0.5516 - loss: 1.0822 - val_accuracy: 0.2616 - val_loss: 1.3857\nEpoch 2/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 838ms/step - accuracy: 0.8258 - loss: 0.4273 - val_accuracy: 0.3050 - val_loss: 1.3876\nEpoch 3/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 804ms/step - accuracy: 0.8435 - loss: 0.3799 - val_accuracy: 0.2508 - val_loss: 1.4002\nEpoch 4/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 805ms/step - accuracy: 0.8765 - loss: 0.3028 - val_accuracy: 0.2508 - val_loss: 1.3952\nEpoch 5/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 806ms/step - accuracy: 0.9255 - loss: 0.1739 - val_accuracy: 0.2508 - val_loss: 1.4577\nEpoch 6/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 811ms/step - accuracy: 0.9207 - loss: 0.2006 - val_accuracy: 0.2508 - val_loss: 2.2156\nEpoch 7/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9363 - loss: 0.1509 - val_accuracy: 0.2508 - val_loss: 3.1301\nEpoch 8/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 830ms/step - accuracy: 0.9354 - loss: 0.1677 - val_accuracy: 0.4536 - val_loss: 1.4119\nEpoch 9/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 833ms/step - accuracy: 0.9579 - loss: 0.1080 - val_accuracy: 0.6285 - val_loss: 0.8735\nEpoch 10/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 833ms/step - accuracy: 0.9564 - loss: 0.1539 - val_accuracy: 0.6641 - val_loss: 1.9182\nEpoch 11/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 811ms/step - accuracy: 0.9515 - loss: 0.1462 - val_accuracy: 0.6424 - val_loss: 1.5797\nEpoch 12/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9610 - loss: 0.1093 - val_accuracy: 0.6146 - val_loss: 2.4342\nEpoch 13/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 831ms/step - accuracy: 0.9688 - loss: 0.0818 - val_accuracy: 0.6749 - val_loss: 1.9504\nEpoch 14/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 832ms/step - accuracy: 0.9707 - loss: 0.0747 - val_accuracy: 0.7786 - val_loss: 0.8506\nEpoch 15/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9733 - loss: 0.0827 - val_accuracy: 0.4923 - val_loss: 6.3736\nEpoch 16/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 811ms/step - accuracy: 0.9703 - loss: 0.0884 - val_accuracy: 0.4040 - val_loss: 7.3200\nEpoch 17/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 834ms/step - accuracy: 0.9767 - loss: 0.0646 - val_accuracy: 0.8406 - val_loss: 0.8840\nEpoch 18/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 832ms/step - accuracy: 0.9809 - loss: 0.0613 - val_accuracy: 0.9040 - val_loss: 0.3446\nEpoch 19/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 811ms/step - accuracy: 0.9785 - loss: 0.0631 - val_accuracy: 0.8096 - val_loss: 1.1585\nEpoch 20/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 811ms/step - accuracy: 0.9800 - loss: 0.0583 - val_accuracy: 0.7028 - val_loss: 2.3839\nEpoch 21/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 809ms/step - accuracy: 0.9857 - loss: 0.0529 - val_accuracy: 0.7585 - val_loss: 1.3224\nEpoch 22/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 832ms/step - accuracy: 0.9788 - loss: 0.0632 - val_accuracy: 0.9489 - val_loss: 0.1967\nEpoch 23/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 809ms/step - accuracy: 0.9876 - loss: 0.0392 - val_accuracy: 0.7539 - val_loss: 1.2628\nEpoch 24/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 805ms/step - accuracy: 0.9809 - loss: 0.0457 - val_accuracy: 0.4598 - val_loss: 4.5524\nEpoch 25/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 806ms/step - accuracy: 0.9702 - loss: 0.0817 - val_accuracy: 0.7353 - val_loss: 2.8555\nEpoch 26/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9769 - loss: 0.0675 - val_accuracy: 0.7167 - val_loss: 2.9046\nEpoch 27/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9845 - loss: 0.0475 - val_accuracy: 0.8854 - val_loss: 0.3909\nEpoch 28/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9828 - loss: 0.0537 - val_accuracy: 0.6486 - val_loss: 3.1334\nEpoch 29/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 808ms/step - accuracy: 0.9844 - loss: 0.0368 - val_accuracy: 0.8251 - val_loss: 0.8027\nEpoch 30/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 808ms/step - accuracy: 0.9813 - loss: 0.0451 - val_accuracy: 0.8111 - val_loss: 0.7502\nEpoch 31/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 809ms/step - accuracy: 0.9909 - loss: 0.0315 - val_accuracy: 0.8947 - val_loss: 0.4546\nEpoch 32/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 811ms/step - accuracy: 0.9895 - loss: 0.0274 - val_accuracy: 0.8731 - val_loss: 0.5235\nEpoch 33/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9921 - loss: 0.0245 - val_accuracy: 0.8080 - val_loss: 0.7061\nEpoch 34/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9808 - loss: 0.0444 - val_accuracy: 0.8065 - val_loss: 1.0275\nEpoch 35/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 811ms/step - accuracy: 0.9938 - loss: 0.0162 - val_accuracy: 0.8762 - val_loss: 0.8309\nEpoch 36/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 809ms/step - accuracy: 0.9891 - loss: 0.0264 - val_accuracy: 0.7384 - val_loss: 1.7197\nEpoch 37/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9917 - loss: 0.0183 - val_accuracy: 0.9443 - val_loss: 0.2607\nEpoch 38/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9902 - loss: 0.0240 - val_accuracy: 0.8978 - val_loss: 0.4455\nEpoch 39/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 809ms/step - accuracy: 0.9956 - loss: 0.0156 - val_accuracy: 0.8560 - val_loss: 0.6010\nEpoch 40/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 811ms/step - accuracy: 0.9916 - loss: 0.0240 - val_accuracy: 0.9412 - val_loss: 0.1928\nEpoch 41/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 811ms/step - accuracy: 0.9943 - loss: 0.0150 - val_accuracy: 0.8390 - val_loss: 1.2888\nEpoch 42/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 808ms/step - accuracy: 0.9716 - loss: 0.0796 - val_accuracy: 0.7585 - val_loss: 1.4369\nEpoch 43/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 806ms/step - accuracy: 0.9909 - loss: 0.0398 - val_accuracy: 0.7570 - val_loss: 1.4869\nEpoch 44/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 808ms/step - accuracy: 0.9781 - loss: 0.0797 - val_accuracy: 0.8901 - val_loss: 0.3397\nEpoch 45/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 809ms/step - accuracy: 0.9792 - loss: 0.0530 - val_accuracy: 0.8947 - val_loss: 0.4231\nEpoch 46/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 809ms/step - accuracy: 0.9910 - loss: 0.0277 - val_accuracy: 0.9303 - val_loss: 0.2442\nEpoch 47/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 811ms/step - accuracy: 0.9934 - loss: 0.0227 - val_accuracy: 0.8808 - val_loss: 0.4511\nEpoch 48/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 834ms/step - accuracy: 0.9913 - loss: 0.0287 - val_accuracy: 0.9613 - val_loss: 0.1591\nEpoch 49/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9833 - loss: 0.0425 - val_accuracy: 0.8669 - val_loss: 0.8249\nEpoch 50/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 811ms/step - accuracy: 0.9885 - loss: 0.0506 - val_accuracy: 0.8622 - val_loss: 0.4821\nEpoch 51/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 811ms/step - accuracy: 0.9869 - loss: 0.0476 - val_accuracy: 0.8266 - val_loss: 1.1361\nEpoch 52/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 811ms/step - accuracy: 0.9811 - loss: 0.0634 - val_accuracy: 0.7012 - val_loss: 1.7265\nEpoch 53/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 811ms/step - accuracy: 0.9872 - loss: 0.0369 - val_accuracy: 0.8452 - val_loss: 0.9048\nEpoch 54/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 809ms/step - accuracy: 0.9961 - loss: 0.0183 - val_accuracy: 0.9288 - val_loss: 0.2861\nEpoch 55/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9982 - loss: 0.0087 - val_accuracy: 0.8406 - val_loss: 0.8471\nEpoch 56/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9912 - loss: 0.0187 - val_accuracy: 0.9118 - val_loss: 0.3561\nEpoch 57/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 809ms/step - accuracy: 0.9972 - loss: 0.0108 - val_accuracy: 0.9489 - val_loss: 0.1684\nEpoch 58/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 811ms/step - accuracy: 0.9942 - loss: 0.0176 - val_accuracy: 0.9396 - val_loss: 0.2119\nEpoch 59/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 811ms/step - accuracy: 0.9949 - loss: 0.0190 - val_accuracy: 0.9350 - val_loss: 0.3275\nEpoch 60/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9949 - loss: 0.0180 - val_accuracy: 0.6672 - val_loss: 2.9191\nEpoch 61/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9895 - loss: 0.0253 - val_accuracy: 0.8901 - val_loss: 0.6134\nEpoch 62/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 809ms/step - accuracy: 0.9941 - loss: 0.0157 - val_accuracy: 0.9241 - val_loss: 0.3512\nEpoch 63/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 809ms/step - accuracy: 0.9879 - loss: 0.0223 - val_accuracy: 0.9427 - val_loss: 0.2588\nEpoch 64/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 808ms/step - accuracy: 0.9933 - loss: 0.0140 - val_accuracy: 0.9350 - val_loss: 0.2898\nEpoch 65/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9969 - loss: 0.0119 - val_accuracy: 0.9087 - val_loss: 0.3975\nEpoch 66/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 811ms/step - accuracy: 0.9978 - loss: 0.0070 - val_accuracy: 0.9505 - val_loss: 0.1995\nEpoch 67/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 809ms/step - accuracy: 0.9936 - loss: 0.0199 - val_accuracy: 0.7616 - val_loss: 1.5257\nEpoch 68/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 807ms/step - accuracy: 0.9703 - loss: 0.0706 - val_accuracy: 0.6393 - val_loss: 3.1279\nEpoch 69/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 809ms/step - accuracy: 0.9723 - loss: 0.0844 - val_accuracy: 0.4582 - val_loss: 5.0101\nEpoch 70/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9795 - loss: 0.0573 - val_accuracy: 0.5836 - val_loss: 4.5750\nEpoch 71/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 809ms/step - accuracy: 0.9848 - loss: 0.0557 - val_accuracy: 0.7601 - val_loss: 1.2723\nEpoch 72/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 808ms/step - accuracy: 0.9886 - loss: 0.0304 - val_accuracy: 0.8963 - val_loss: 0.3747\nEpoch 73/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 809ms/step - accuracy: 0.9925 - loss: 0.0377 - val_accuracy: 0.8607 - val_loss: 0.5455\nEpoch 74/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 809ms/step - accuracy: 0.9915 - loss: 0.0252 - val_accuracy: 0.8653 - val_loss: 0.6473\nEpoch 75/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 809ms/step - accuracy: 0.9940 - loss: 0.0173 - val_accuracy: 0.7399 - val_loss: 1.7119\nEpoch 76/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9937 - loss: 0.0175 - val_accuracy: 0.7554 - val_loss: 1.3039\nEpoch 77/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9857 - loss: 0.0426 - val_accuracy: 0.8467 - val_loss: 0.7904\nEpoch 78/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 809ms/step - accuracy: 0.9835 - loss: 0.0482 - val_accuracy: 0.6935 - val_loss: 2.7952\nEpoch 79/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 806ms/step - accuracy: 0.9847 - loss: 0.0557 - val_accuracy: 0.4365 - val_loss: 9.2475\nEpoch 80/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 807ms/step - accuracy: 0.9935 - loss: 0.0178 - val_accuracy: 0.8282 - val_loss: 0.9334\nEpoch 81/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 811ms/step - accuracy: 0.9882 - loss: 0.0475 - val_accuracy: 0.7384 - val_loss: 2.1966\nEpoch 82/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9922 - loss: 0.0273 - val_accuracy: 0.8483 - val_loss: 0.7090\nEpoch 83/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9893 - loss: 0.0277 - val_accuracy: 0.8916 - val_loss: 0.4587\nEpoch 84/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 811ms/step - accuracy: 0.9964 - loss: 0.0154 - val_accuracy: 0.8669 - val_loss: 0.6308\nEpoch 85/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 834ms/step - accuracy: 0.9971 - loss: 0.0082 - val_accuracy: 0.9628 - val_loss: 0.1370\nEpoch 86/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 833ms/step - accuracy: 0.9963 - loss: 0.0075 - val_accuracy: 0.9659 - val_loss: 0.1826\nEpoch 87/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 811ms/step - accuracy: 0.9966 - loss: 0.0089 - val_accuracy: 0.9350 - val_loss: 0.3108\nEpoch 88/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9959 - loss: 0.0133 - val_accuracy: 0.9334 - val_loss: 0.2692\nEpoch 89/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 809ms/step - accuracy: 0.9970 - loss: 0.0089 - val_accuracy: 0.8715 - val_loss: 0.6265\nEpoch 90/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9907 - loss: 0.0218 - val_accuracy: 0.8793 - val_loss: 0.5978\nEpoch 91/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 809ms/step - accuracy: 0.9984 - loss: 0.0058 - val_accuracy: 0.9474 - val_loss: 0.1692\nEpoch 92/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9978 - loss: 0.0104 - val_accuracy: 0.8560 - val_loss: 0.7873\nEpoch 93/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 811ms/step - accuracy: 0.9993 - loss: 0.0042 - val_accuracy: 0.9211 - val_loss: 0.2962\nEpoch 94/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 808ms/step - accuracy: 0.9946 - loss: 0.0172 - val_accuracy: 0.5991 - val_loss: 4.1633\nEpoch 95/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 807ms/step - accuracy: 0.9905 - loss: 0.0248 - val_accuracy: 0.7229 - val_loss: 2.0019\nEpoch 96/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 807ms/step - accuracy: 0.9945 - loss: 0.0189 - val_accuracy: 0.9040 - val_loss: 0.6289\nEpoch 97/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9940 - loss: 0.0164 - val_accuracy: 0.9350 - val_loss: 0.2434\nEpoch 98/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 834ms/step - accuracy: 0.9959 - loss: 0.0101 - val_accuracy: 0.9783 - val_loss: 0.0837\nEpoch 99/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 810ms/step - accuracy: 0.9982 - loss: 0.0084 - val_accuracy: 0.8467 - val_loss: 0.8701\nEpoch 100/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 811ms/step - accuracy: 0.9938 - loss: 0.0146 - val_accuracy: 0.9505 - val_loss: 0.1699\nskip\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"a = 5\nwhile(True):\n    a = 10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T05:10:56.932220Z","iopub.execute_input":"2025-01-31T05:10:56.932554Z"}},"outputs":[],"execution_count":null}]}