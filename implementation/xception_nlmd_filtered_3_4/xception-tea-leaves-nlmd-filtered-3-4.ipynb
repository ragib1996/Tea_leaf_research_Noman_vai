{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10602688,"sourceType":"datasetVersion","datasetId":6527737}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow import keras\nfrom keras.models import Model\nfrom keras import layers\nfrom keras.layers import Dense, Input, BatchNormalization, Activation\nfrom keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n#from keras.applications.imagenet_utils import _obtain_input_shape\n#from keras.utils.data_utils import get_file\nfrom sklearn.model_selection import KFold\nfrom keras.datasets import mnist\nfrom PIL import Image\n# for creating a one hot vector for labels\n#from keras.utils import np_utils\nfrom IPython.display import display, Image\n#import the models\nfrom keras import Model\n#add layers\nfrom keras import layers\n#add optimizer\nfrom keras import optimizers\n#add loss function \nfrom keras import losses\nimport random\n\nimport keras\nimport numpy as np\nimport pandas as pd \nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport tensorflow.keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-31T09:22:43.447948Z","iopub.execute_input":"2025-01-31T09:22:43.448210Z","iopub.status.idle":"2025-01-31T09:22:56.245768Z","shell.execute_reply.started":"2025-01-31T09:22:43.448175Z","shell.execute_reply":"2025-01-31T09:22:56.245096Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from tensorflow import keras\nfrom keras.models import Model\nfrom keras.layers import Dense, Input, BatchNormalization, Activation\nfrom keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom IPython.core.display import display, HTML\nimport sys\n\n# Adjust notebook display width\ndisplay(HTML(\"<style>.container { width:90% !important; }</style>\"))\n\n\nimg_size = 299\ndef Xception():\n\n\t# Determine proper input shape\n\tinput_shape = (img_size, img_size, 3 )#_obtain_input_shape(None, default_size=299, min_size=71, data_format='channels_last', include_top=False)\n\n\timg_input = Input(shape=input_shape)\n\n\t# Block 1\n\tx = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False)(img_input)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = Conv2D(64, (3, 3), use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\n\tresidual = Conv2D(128, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n\tresidual = BatchNormalization()(residual)\n\n\t# Block 2\n\tx = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\n\t# Block 2 Pool\n\tx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\tx = layers.add([x, residual])\n\n\tresidual = Conv2D(256, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n\tresidual = BatchNormalization()(residual)\n\n\t# Block 3\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\n\t# Block 3 Pool\n\tx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\tx = layers.add([x, residual])\n\n\tresidual = Conv2D(728, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n\tresidual = BatchNormalization()(residual)\n\n\t# Block 4\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\n\tx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\tx = layers.add([x, residual])\n\n\t# Block 5 - 12\n\tfor i in range(8):\n\t\tresidual = x\n\n\t\tx = Activation('relu')(x)\n\t\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\t\tx = BatchNormalization()(x)\n\t\tx = Activation('relu')(x)\n\t\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\t\tx = BatchNormalization()(x)\n\t\tx = Activation('relu')(x)\n\t\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\t\tx = BatchNormalization()(x)\n\n\t\tx = layers.add([x, residual])\n\n\tresidual = Conv2D(1024, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n\tresidual = BatchNormalization()(residual)\n\n\t# Block 13\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(1024, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\n\t# Block 13 Pool\n\tx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\tx = layers.add([x, residual])\n\n\t# Block 14\n\tx = SeparableConv2D(1536, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\n\t# Block 14 part 2\n\tx = SeparableConv2D(2048, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\n\t# Fully Connected Layer\n\tx = GlobalAveragePooling2D()(x)\n\tx = Dense( 4 , activation='softmax')(x)\n\n\tinputs = img_input\n\n\t# Create model\n\tmodel = Model(inputs, x, name='xception')\n\n\t# Download and cache the Xception weights file\n\n\n\treturn model\n\nmodel = Xception()\n\nmodel.compile(\n    optimizer='Adam',\n    loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n    metrics=[\"accuracy\"],\n)\n\n# Print the model summary\nmodel.summary(print_fn=lambda x: sys.stdout.write(x + '\\n'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T09:22:56.246483Z","iopub.execute_input":"2025-01-31T09:22:56.246913Z","iopub.status.idle":"2025-01-31T09:22:59.196085Z","shell.execute_reply.started":"2025-01-31T09:22:56.246891Z","shell.execute_reply":"2025-01-31T09:22:59.195249Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>.container { width:90% !important; }</style>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"name":"stdout","text":"Model: \"xception\"\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃ Layer (type)              ┃ Output Shape           ┃        Param # ┃ Connected to           ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (InputLayer)  │ (None, 299, 299, 3)    │              0 │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d (Conv2D)           │ (None, 149, 149, 32)   │            864 │ input_layer[0][0]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization       │ (None, 149, 149, 32)   │            128 │ conv2d[0][0]           │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation (Activation)   │ (None, 149, 149, 32)   │              0 │ batch_normalization[0… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_1 (Conv2D)         │ (None, 147, 147, 64)   │         18,432 │ activation[0][0]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_1     │ (None, 147, 147, 64)   │            256 │ conv2d_1[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_1 (Activation) │ (None, 147, 147, 64)   │              0 │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d          │ (None, 147, 147, 128)  │          8,768 │ activation_1[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_3     │ (None, 147, 147, 128)  │            512 │ separable_conv2d[0][0] │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_2 (Activation) │ (None, 147, 147, 128)  │              0 │ batch_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_1        │ (None, 147, 147, 128)  │         17,536 │ activation_2[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_4     │ (None, 147, 147, 128)  │            512 │ separable_conv2d_1[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_2 (Conv2D)         │ (None, 74, 74, 128)    │          8,192 │ activation_1[0][0]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d             │ (None, 74, 74, 128)    │              0 │ batch_normalization_4… │\n│ (MaxPooling2D)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_2     │ (None, 74, 74, 128)    │            512 │ conv2d_2[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add (Add)                 │ (None, 74, 74, 128)    │              0 │ max_pooling2d[0][0],   │\n│                           │                        │                │ batch_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_3 (Activation) │ (None, 74, 74, 128)    │              0 │ add[0][0]              │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_2        │ (None, 74, 74, 256)    │         33,920 │ activation_3[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_6     │ (None, 74, 74, 256)    │          1,024 │ separable_conv2d_2[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_4 (Activation) │ (None, 74, 74, 256)    │              0 │ batch_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_3        │ (None, 74, 74, 256)    │         67,840 │ activation_4[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_7     │ (None, 74, 74, 256)    │          1,024 │ separable_conv2d_3[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_3 (Conv2D)         │ (None, 37, 37, 256)    │         32,768 │ add[0][0]              │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_1           │ (None, 37, 37, 256)    │              0 │ batch_normalization_7… │\n│ (MaxPooling2D)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_5     │ (None, 37, 37, 256)    │          1,024 │ conv2d_3[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_1 (Add)               │ (None, 37, 37, 256)    │              0 │ max_pooling2d_1[0][0], │\n│                           │                        │                │ batch_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_5 (Activation) │ (None, 37, 37, 256)    │              0 │ add_1[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_4        │ (None, 37, 37, 728)    │        188,672 │ activation_5[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_9     │ (None, 37, 37, 728)    │          2,912 │ separable_conv2d_4[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_6 (Activation) │ (None, 37, 37, 728)    │              0 │ batch_normalization_9… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_5        │ (None, 37, 37, 728)    │        536,536 │ activation_6[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_10    │ (None, 37, 37, 728)    │          2,912 │ separable_conv2d_5[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_4 (Conv2D)         │ (None, 19, 19, 728)    │        186,368 │ add_1[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_2           │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (MaxPooling2D)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_8     │ (None, 19, 19, 728)    │          2,912 │ conv2d_4[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_2 (Add)               │ (None, 19, 19, 728)    │              0 │ max_pooling2d_2[0][0], │\n│                           │                        │                │ batch_normalization_8… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_7 (Activation) │ (None, 19, 19, 728)    │              0 │ add_2[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_6        │ (None, 19, 19, 728)    │        536,536 │ activation_7[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_11    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_6[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_8 (Activation) │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_7        │ (None, 19, 19, 728)    │        536,536 │ activation_8[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_12    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_7[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_9 (Activation) │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_8        │ (None, 19, 19, 728)    │        536,536 │ activation_9[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_13    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_8[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_3 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│                           │                        │                │ add_2[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_10             │ (None, 19, 19, 728)    │              0 │ add_3[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_9        │ (None, 19, 19, 728)    │        536,536 │ activation_10[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_14    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_9[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_11             │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_10       │ (None, 19, 19, 728)    │        536,536 │ activation_11[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_15    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_10[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_12             │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_11       │ (None, 19, 19, 728)    │        536,536 │ activation_12[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_16    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_11[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_4 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│                           │                        │                │ add_3[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_13             │ (None, 19, 19, 728)    │              0 │ add_4[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_12       │ (None, 19, 19, 728)    │        536,536 │ activation_13[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_17    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_12[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_14             │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_13       │ (None, 19, 19, 728)    │        536,536 │ activation_14[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_18    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_13[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_15             │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_14       │ (None, 19, 19, 728)    │        536,536 │ activation_15[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_19    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_14[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_5 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│                           │                        │                │ add_4[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_16             │ (None, 19, 19, 728)    │              0 │ add_5[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_15       │ (None, 19, 19, 728)    │        536,536 │ activation_16[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_20    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_15[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_17             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_16       │ (None, 19, 19, 728)    │        536,536 │ activation_17[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_21    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_16[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_18             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_17       │ (None, 19, 19, 728)    │        536,536 │ activation_18[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_22    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_17[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_6 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│                           │                        │                │ add_5[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_19             │ (None, 19, 19, 728)    │              0 │ add_6[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_18       │ (None, 19, 19, 728)    │        536,536 │ activation_19[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_23    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_18[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_20             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_19       │ (None, 19, 19, 728)    │        536,536 │ activation_20[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_24    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_19[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_21             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_20       │ (None, 19, 19, 728)    │        536,536 │ activation_21[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_25    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_20[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_7 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│                           │                        │                │ add_6[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_22             │ (None, 19, 19, 728)    │              0 │ add_7[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_21       │ (None, 19, 19, 728)    │        536,536 │ activation_22[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_26    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_21[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_23             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_22       │ (None, 19, 19, 728)    │        536,536 │ activation_23[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_27    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_22[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_24             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_23       │ (None, 19, 19, 728)    │        536,536 │ activation_24[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_28    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_23[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_8 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│                           │                        │                │ add_7[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_25             │ (None, 19, 19, 728)    │              0 │ add_8[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_24       │ (None, 19, 19, 728)    │        536,536 │ activation_25[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_29    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_24[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_26             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_25       │ (None, 19, 19, 728)    │        536,536 │ activation_26[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_30    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_25[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_27             │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_26       │ (None, 19, 19, 728)    │        536,536 │ activation_27[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_31    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_26[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_9 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│                           │                        │                │ add_8[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_28             │ (None, 19, 19, 728)    │              0 │ add_9[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_27       │ (None, 19, 19, 728)    │        536,536 │ activation_28[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_32    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_27[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_29             │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_28       │ (None, 19, 19, 728)    │        536,536 │ activation_29[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_33    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_28[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_30             │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_29       │ (None, 19, 19, 728)    │        536,536 │ activation_30[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_34    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_29[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_10 (Add)              │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│                           │                        │                │ add_9[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_31             │ (None, 19, 19, 728)    │              0 │ add_10[0][0]           │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_30       │ (None, 19, 19, 728)    │        536,536 │ activation_31[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_36    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_30[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_32             │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_31       │ (None, 19, 19, 1024)   │        752,024 │ activation_32[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_37    │ (None, 19, 19, 1024)   │          4,096 │ separable_conv2d_31[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_5 (Conv2D)         │ (None, 10, 10, 1024)   │        745,472 │ add_10[0][0]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_3           │ (None, 10, 10, 1024)   │              0 │ batch_normalization_3… │\n│ (MaxPooling2D)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_35    │ (None, 10, 10, 1024)   │          4,096 │ conv2d_5[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_11 (Add)              │ (None, 10, 10, 1024)   │              0 │ max_pooling2d_3[0][0], │\n│                           │                        │                │ batch_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_32       │ (None, 10, 10, 1536)   │      1,582,080 │ add_11[0][0]           │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_38    │ (None, 10, 10, 1536)   │          6,144 │ separable_conv2d_32[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_33             │ (None, 10, 10, 1536)   │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_33       │ (None, 10, 10, 2048)   │      3,159,552 │ activation_33[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_39    │ (None, 10, 10, 2048)   │          8,192 │ separable_conv2d_33[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_34             │ (None, 10, 10, 2048)   │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d  │ (None, 2048)           │              0 │ activation_34[0][0]    │\n│ (GlobalAveragePooling2D)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (Dense)             │ (None, 4)              │          8,196 │ global_average_poolin… │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n Total params: 20,869,676 (79.61 MB)\n Trainable params: 20,815,148 (79.40 MB)\n Non-trainable params: 54,528 (213.00 KB)\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"x = []\nlabel = []\nx_validation = []\nlabel_validation = []\nx_test = []\nlabel_test = []\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T09:22:59.196811Z","iopub.execute_input":"2025-01-31T09:22:59.197025Z","iopub.status.idle":"2025-01-31T09:22:59.200690Z","shell.execute_reply.started":"2025-01-31T09:22:59.196999Z","shell.execute_reply":"2025-01-31T09:22:59.199857Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"csv_file = pd.read_csv(\"/kaggle/input/tea-image-dataset-nlmd-filtered/splited_into_5_fold.csv\")\nprint(csv_file)\n\nfolded = csv_file.groupby(\"fold\")\ntemp_image_name = \"\"\ntemp_image = []\nfor i,j in folded:\n    if i == 3: # testing\n        print(\"fold \"+str(i))\n        cat = j.groupby(\"category\")\n        for k,l in cat:\n            if k == \"Brown_blight\":\n                brown_blight_image_name = l['image_name']\n                brown_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Brown_blight\"\n                \n                for m in brown_blight_image_name:\n                    brown_blight_image = cv2.imread(brown_blight_link + '/'+\"nlmd_\"+m)\n                    brown_blight_image = cv2.resize( brown_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = brown_blight_image\n                    \"\"\"\n                    x_test.append(brown_blight_image)\n                    label_test.append([0])\n                print(len(x_test),\" \",len(label_test))\n                    \n            if k == \"Grey_blight\":\n                grey_blight_image_name = l['image_name']    \n                grey_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Grey_blight\"\n\n                for m in grey_blight_image_name:\n                    grey_blight_image = cv2.imread(grey_blight_link + '/'+\"nlmd_\"+m)\n                    grey_blight_image = cv2.resize( grey_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = grey_blight_image\n                    \"\"\"\n                    x_test.append(grey_blight_image)\n                    label_test.append([1])\n                print(len(x_test),\" \",len(label_test))\n                    \n            if k == \"Healthy\":\n                healthy_image_name = l['image_name']    \n                healthy_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Healthy\"\n\n                for m in healthy_image_name:\n                    healthy_image = cv2.imread(healthy_link + '/'+\"nlmd_\"+m)\n                    healthy_image = cv2.resize( healthy_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = healthy_image\n                    \"\"\"\n                    x_test.append( healthy_image)\n                    label_test.append([2])\n                print(len(x_test),\" \",len(label_test))\n\n            if k == \"Red_rust\":\n                red_rust_image_name = l['image_name']\n                red_rust_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Red_rust\"\n\n                for m in red_rust_image_name:\n                    red_rust_image = cv2.imread(red_rust_link+ '/' + \"nlmd_\"+m)\n                    red_rust_image = cv2.resize(red_rust_image, (img_size, img_size))\n                    x_test.append(red_rust_image)\n                    label_test.append([3])\n                print(len(x_test),\" \", len(label_test))\n            \n    \n    elif i == 4: # validation\n        print(\"fold \"+str(i))\n        cat = j.groupby(\"category\")\n        for k,l in cat:\n            if k == \"Brown_blight\":\n                brown_blight_image_name = l['image_name']\n                brown_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Brown_blight\"\n                \n                for m in brown_blight_image_name:\n                    brown_blight_image = cv2.imread(brown_blight_link + '/'+\"nlmd_\"+m)\n                    brown_blight_image = cv2.resize(brown_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = brown_blight_image\n                    \"\"\"\n                    x_validation.append(brown_blight_image)\n                    label_validation.append([0])\n                print(len(x_validation),\" \",len(label_validation))\n                    \n            if k == \"Grey_blight\":\n                grey_blight_image_name = l['image_name']    \n                grey_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Grey_blight\"\n\n                for m in grey_blight_image_name:\n                    grey_blight_image = cv2.imread(grey_blight_link + '/'+\"nlmd_\"+m)\n                    grey_blight_image = cv2.resize( grey_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = grey_blight_image\n                    \"\"\"\n                    x_validation.append(grey_blight_image)\n                    label_validation.append([1])\n                print(len(x_validation),\" \",len(label_validation))\n                    \n            if k == \"Healthy\":\n                healthy_image_name = l['image_name']    \n                healthy_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Healthy\"\n\n                for m in healthy_image_name:\n                    healthy_image = cv2.imread(healthy_link + '/'+\"nlmd_\"+m)\n                    healthy_image =  cv2.resize(healthy_image , ( img_size , img_size ))\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = healthy_image\n                    x_validation.append( healthy_image)\n                    label_validation.append([2])\n                print(len(x_validation),\" \",len(label_validation))\n                \n            if k == \"Red_rust\":\n                red_rust_image_name = l['image_name']\n                red_rust_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Red_rust\"\n\n                for m in red_rust_image_name:\n                    red_rust_image = cv2.imread(red_rust_link+ '/' + \"nlmd_\"+m)\n                    red_rust_image = cv2.resize(red_rust_image, (img_size, img_size))\n                    x_validation.append(red_rust_image)\n                    label_validation.append([3])\n                print(len(x_validation),\" \", len(label_validation))\n            \n\n    else: # training\n        print(\"fold \"+str(i))\n        cat = j.groupby(\"category\")\n        for k,l in cat:\n            if k == \"Brown_blight\":\n                brown_blight_image_name = l['image_name']\n                brown_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Brown_blight\"\n                \n                for m in brown_blight_image_name:\n                    brown_blight_image = cv2.imread(brown_blight_link + '/'+\"nlmd_\"+m)\n                    brown_blight_image = cv2.resize(brown_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = brown_blight_image\n                    \"\"\"\n                    x.append(brown_blight_image)\n                    label.append([0])\n                print(len(x),\" \",len(label))\n            if k == \"Grey_blight\":\n                grey_blight_image_name = l['image_name']    \n                grey_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Grey_blight\"\n\n                for m in grey_blight_image_name:\n                    grey_blight_image = cv2.imread(grey_blight_link + '/'+\"nlmd_\"+m)\n                    grey_blight_image = cv2.resize( grey_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = grey_blight_image\n                    \"\"\"\n                    x.append(grey_blight_image)\n                    label.append([1])\n                print(len(x),\" \",len(label))\n                    \n            if k == \"Healthy\":\n                healthy_image_name = l['image_name']    \n                healthy_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Healthy\"\n\n                for m in healthy_image_name:\n                    healthy_image = cv2.imread(healthy_link + '/'+\"nlmd_\"+m)\n                    healthy_image =  cv2.resize(healthy_image , ( img_size , img_size ))\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = healthy_image\n                    x.append( healthy_image)\n                    label.append([2])\n                print(len(x),\" \",len(label))\n                \n            if k == \"Red_rust\":\n                red_rust_image_name = l['image_name']\n                red_rust_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Red_rust\"\n\n                for m in red_rust_image_name:\n                    red_rust_image = cv2.imread(red_rust_link+ '/' + \"nlmd_\"+m)\n                    red_rust_image = cv2.resize(red_rust_image, (img_size, img_size))\n                    x.append(red_rust_image)\n                    label.append([3])\n                print(len(x),\" \", len(label))\n            \n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T09:22:59.202521Z","iopub.execute_input":"2025-01-31T09:22:59.202738Z","iopub.status.idle":"2025-01-31T09:26:42.360982Z","shell.execute_reply.started":"2025-01-31T09:22:59.202719Z","shell.execute_reply":"2025-01-31T09:26:42.360022Z"}},"outputs":[{"name":"stdout","text":"                 image_name  fold      category\n0      Training_img_280.jpg     0  Brown_blight\n1      Training_img_662.jpg     0  Brown_blight\n2      Training_img_651.jpg     0  Brown_blight\n3      Training_img_809.jpg     0  Brown_blight\n4      Training_img_546.jpg     0  Brown_blight\n...                     ...   ...           ...\n3229  Training_img_2989.jpg     4      Red_rust\n3230  Training_img_2880.jpg     4      Red_rust\n3231  Training_img_2693.jpg     4      Red_rust\n3232  Training_img_2997.jpg     4      Red_rust\n3233  Training_img_2993.jpg     4      Red_rust\n\n[3234 rows x 3 columns]\nfold 0\n159   159\n329   329\n491   491\n649   649\nfold 1\n808   808\n977   977\n1139   1139\n1297   1297\nfold 2\n1455   1455\n1624   1624\n1786   1786\n1943   1943\nfold 3\n158   158\n327   327\n489   489\n646   646\nfold 4\n158   158\n327   327\n488   488\n645   645\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"print(len(x),\" \",len(label))\nprint(len(x_validation),\" \",len(label_validation))\nprint(len(x_test),\" \",len(label_test))\nprint(\"Hello world.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T09:26:42.362595Z","iopub.execute_input":"2025-01-31T09:26:42.362874Z","iopub.status.idle":"2025-01-31T09:26:42.369458Z","shell.execute_reply.started":"2025-01-31T09:26:42.362852Z","shell.execute_reply":"2025-01-31T09:26:42.368674Z"}},"outputs":[{"name":"stdout","text":"1943   1943\n645   645\n646   646\nHello world.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"x = np.asarray(x)\nx_validation = np.asarray(x_validation)\nx_test = np.asarray(x_test)\n\nprint(len(x),\" \", len(x_validation),\" \", len(x_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T09:26:42.370348Z","iopub.execute_input":"2025-01-31T09:26:42.370629Z","iopub.status.idle":"2025-01-31T09:26:42.606420Z","shell.execute_reply.started":"2025-01-31T09:26:42.370601Z","shell.execute_reply":"2025-01-31T09:26:42.605544Z"}},"outputs":[{"name":"stdout","text":"1943   645   646\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical \n\nlabel = np.array(label)\nlabel = to_categorical(label , 4 )\nprint(len(label))\n\n\n\nlabel = np.array(label)\nlabel_validation = to_categorical(label_validation , 4 )\nprint(len(label_validation))\n\nlabel = np.array(label)\nlabel_test = to_categorical(label_test , 4 )\nprint(len(label_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T09:26:42.607285Z","iopub.execute_input":"2025-01-31T09:26:42.607627Z","iopub.status.idle":"2025-01-31T09:26:42.618150Z","shell.execute_reply.started":"2025-01-31T09:26:42.607590Z","shell.execute_reply":"2025-01-31T09:26:42.617361Z"}},"outputs":[{"name":"stdout","text":"1943\n645\n646\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"print(label[491])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T09:26:42.618951Z","iopub.execute_input":"2025-01-31T09:26:42.619201Z","iopub.status.idle":"2025-01-31T09:26:42.627744Z","shell.execute_reply.started":"2025-01-31T09:26:42.619177Z","shell.execute_reply":"2025-01-31T09:26:42.627027Z"}},"outputs":[{"name":"stdout","text":"[0. 0. 0. 1.]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"early_stop  = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience= 90 , verbose=0, mode='max')\n#check_point = tf.keras.callbacks.ModelCheckpoint('/kaggle/working/xception_tea_leaves_nlmd_filtered.h5', monitor='val_acc', save_best_only=True, mode='max')\ncheck_point = tf.keras.callbacks.ModelCheckpoint('/kaggle/working/xception_tea_leaves_nlmd_filtered_3_4.keras', monitor='val_accuracy', save_best_only=True, mode='max')\n\nhistory = model.fit(x , label , validation_data = (x_validation , label_validation ), epochs = 100 , callbacks=[early_stop, check_point])\n    \n\nprint(\"skip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T09:26:42.628458Z","iopub.execute_input":"2025-01-31T09:26:42.628691Z","iopub.status.idle":"2025-01-31T10:58:59.686426Z","shell.execute_reply.started":"2025-01-31T09:26:42.628673Z","shell.execute_reply":"2025-01-31T10:58:59.685659Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m183s\u001b[0m 2s/step - accuracy: 0.4698 - loss: 1.2637 - val_accuracy: 0.2620 - val_loss: 1.3846\nEpoch 2/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 893ms/step - accuracy: 0.7104 - loss: 0.7544 - val_accuracy: 0.2620 - val_loss: 1.3858\nEpoch 3/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 879ms/step - accuracy: 0.8048 - loss: 0.5520 - val_accuracy: 0.2620 - val_loss: 1.4173\nEpoch 4/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 877ms/step - accuracy: 0.8747 - loss: 0.3059 - val_accuracy: 0.2620 - val_loss: 1.4494\nEpoch 5/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 880ms/step - accuracy: 0.8951 - loss: 0.2650 - val_accuracy: 0.2620 - val_loss: 1.3835\nEpoch 6/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 905ms/step - accuracy: 0.9261 - loss: 0.2022 - val_accuracy: 0.3147 - val_loss: 1.9164\nEpoch 7/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 907ms/step - accuracy: 0.9240 - loss: 0.1937 - val_accuracy: 0.4574 - val_loss: 1.5371\nEpoch 8/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 884ms/step - accuracy: 0.9155 - loss: 0.1969 - val_accuracy: 0.3984 - val_loss: 1.7614\nEpoch 9/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 906ms/step - accuracy: 0.9312 - loss: 0.2057 - val_accuracy: 0.8047 - val_loss: 0.4712\nEpoch 10/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 881ms/step - accuracy: 0.9641 - loss: 0.1107 - val_accuracy: 0.3488 - val_loss: 6.2472\nEpoch 11/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 908ms/step - accuracy: 0.9572 - loss: 0.1165 - val_accuracy: 0.8651 - val_loss: 0.4201\nEpoch 12/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 884ms/step - accuracy: 0.9658 - loss: 0.1020 - val_accuracy: 0.6093 - val_loss: 2.4021\nEpoch 13/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 887ms/step - accuracy: 0.9503 - loss: 0.1269 - val_accuracy: 0.7721 - val_loss: 0.7547\nEpoch 14/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9606 - loss: 0.0914 - val_accuracy: 0.8078 - val_loss: 0.6603\nEpoch 15/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 883ms/step - accuracy: 0.9576 - loss: 0.1113 - val_accuracy: 0.7845 - val_loss: 1.0686\nEpoch 16/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 879ms/step - accuracy: 0.9776 - loss: 0.0579 - val_accuracy: 0.5860 - val_loss: 2.7214\nEpoch 17/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 882ms/step - accuracy: 0.9680 - loss: 0.1014 - val_accuracy: 0.7240 - val_loss: 1.4140\nEpoch 18/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 884ms/step - accuracy: 0.9687 - loss: 0.0875 - val_accuracy: 0.6961 - val_loss: 1.5808\nEpoch 19/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 884ms/step - accuracy: 0.9822 - loss: 0.0461 - val_accuracy: 0.5318 - val_loss: 4.7303\nEpoch 20/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9641 - loss: 0.0904 - val_accuracy: 0.6946 - val_loss: 1.7053\nEpoch 21/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 887ms/step - accuracy: 0.9642 - loss: 0.0984 - val_accuracy: 0.5721 - val_loss: 5.9693\nEpoch 22/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 887ms/step - accuracy: 0.9700 - loss: 0.0848 - val_accuracy: 0.7767 - val_loss: 0.8132\nEpoch 23/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 911ms/step - accuracy: 0.9837 - loss: 0.0497 - val_accuracy: 0.8915 - val_loss: 0.4047\nEpoch 24/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 888ms/step - accuracy: 0.9715 - loss: 0.0720 - val_accuracy: 0.8047 - val_loss: 1.2254\nEpoch 25/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 884ms/step - accuracy: 0.9701 - loss: 0.0904 - val_accuracy: 0.8062 - val_loss: 0.8986\nEpoch 26/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 880ms/step - accuracy: 0.9567 - loss: 0.1309 - val_accuracy: 0.6713 - val_loss: 2.1900\nEpoch 27/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 880ms/step - accuracy: 0.9679 - loss: 0.0683 - val_accuracy: 0.7426 - val_loss: 0.9547\nEpoch 28/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 906ms/step - accuracy: 0.9850 - loss: 0.0477 - val_accuracy: 0.9504 - val_loss: 0.1779\nEpoch 29/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9879 - loss: 0.0255 - val_accuracy: 0.7984 - val_loss: 0.8243\nEpoch 30/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 888ms/step - accuracy: 0.9932 - loss: 0.0238 - val_accuracy: 0.9070 - val_loss: 0.3163\nEpoch 31/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 888ms/step - accuracy: 0.9922 - loss: 0.0221 - val_accuracy: 0.7736 - val_loss: 0.9877\nEpoch 32/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 888ms/step - accuracy: 0.9947 - loss: 0.0165 - val_accuracy: 0.8791 - val_loss: 0.4892\nEpoch 33/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 888ms/step - accuracy: 0.9961 - loss: 0.0135 - val_accuracy: 0.8946 - val_loss: 0.5066\nEpoch 34/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 887ms/step - accuracy: 0.9881 - loss: 0.0381 - val_accuracy: 0.6946 - val_loss: 1.4000\nEpoch 35/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 884ms/step - accuracy: 0.9481 - loss: 0.1626 - val_accuracy: 0.5070 - val_loss: 5.9871\nEpoch 36/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 883ms/step - accuracy: 0.9887 - loss: 0.0327 - val_accuracy: 0.8636 - val_loss: 0.4787\nEpoch 37/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9895 - loss: 0.0366 - val_accuracy: 0.7597 - val_loss: 1.5286\nEpoch 38/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9892 - loss: 0.0323 - val_accuracy: 0.8310 - val_loss: 0.5297\nEpoch 39/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9772 - loss: 0.0635 - val_accuracy: 0.4791 - val_loss: 4.6584\nEpoch 40/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 888ms/step - accuracy: 0.9898 - loss: 0.0334 - val_accuracy: 0.9132 - val_loss: 0.3861\nEpoch 41/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 883ms/step - accuracy: 0.9944 - loss: 0.0160 - val_accuracy: 0.8434 - val_loss: 0.5664\nEpoch 42/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 909ms/step - accuracy: 0.9972 - loss: 0.0113 - val_accuracy: 0.9690 - val_loss: 0.1395\nEpoch 43/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9982 - loss: 0.0062 - val_accuracy: 0.9690 - val_loss: 0.1167\nEpoch 44/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9916 - loss: 0.0199 - val_accuracy: 0.5442 - val_loss: 3.5541\nEpoch 45/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 888ms/step - accuracy: 0.9940 - loss: 0.0229 - val_accuracy: 0.8698 - val_loss: 0.4286\nEpoch 46/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 888ms/step - accuracy: 0.9969 - loss: 0.0185 - val_accuracy: 0.8760 - val_loss: 0.4572\nEpoch 47/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9853 - loss: 0.0358 - val_accuracy: 0.8496 - val_loss: 0.6030\nEpoch 48/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 888ms/step - accuracy: 0.9879 - loss: 0.0350 - val_accuracy: 0.8217 - val_loss: 0.6890\nEpoch 49/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 887ms/step - accuracy: 0.9861 - loss: 0.0426 - val_accuracy: 0.7752 - val_loss: 1.0859\nEpoch 50/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 887ms/step - accuracy: 0.9914 - loss: 0.0180 - val_accuracy: 0.7953 - val_loss: 1.2763\nEpoch 51/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 887ms/step - accuracy: 0.9944 - loss: 0.0201 - val_accuracy: 0.5225 - val_loss: 4.0181\nEpoch 52/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9815 - loss: 0.0598 - val_accuracy: 0.7690 - val_loss: 1.8929\nEpoch 53/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 888ms/step - accuracy: 0.9867 - loss: 0.0368 - val_accuracy: 0.9302 - val_loss: 0.2450\nEpoch 54/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 888ms/step - accuracy: 0.9918 - loss: 0.0212 - val_accuracy: 0.8760 - val_loss: 0.6044\nEpoch 55/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 888ms/step - accuracy: 0.9967 - loss: 0.0150 - val_accuracy: 0.8651 - val_loss: 0.5252\nEpoch 56/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 888ms/step - accuracy: 0.9971 - loss: 0.0137 - val_accuracy: 0.8434 - val_loss: 0.5168\nEpoch 57/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9988 - loss: 0.0087 - val_accuracy: 0.9054 - val_loss: 0.3608\nEpoch 58/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 904ms/step - accuracy: 0.9978 - loss: 0.0125 - val_accuracy: 0.9721 - val_loss: 0.1220\nEpoch 59/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 885ms/step - accuracy: 0.9979 - loss: 0.0106 - val_accuracy: 0.7767 - val_loss: 1.0930\nEpoch 60/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 889ms/step - accuracy: 0.9988 - loss: 0.0063 - val_accuracy: 0.9628 - val_loss: 0.1682\nEpoch 61/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 889ms/step - accuracy: 0.9951 - loss: 0.0114 - val_accuracy: 0.9039 - val_loss: 0.4793\nEpoch 62/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 888ms/step - accuracy: 0.9983 - loss: 0.0045 - val_accuracy: 0.9457 - val_loss: 0.2324\nEpoch 63/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 887ms/step - accuracy: 0.9973 - loss: 0.0059 - val_accuracy: 0.8512 - val_loss: 0.7075\nEpoch 64/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 887ms/step - accuracy: 0.9966 - loss: 0.0102 - val_accuracy: 0.9395 - val_loss: 0.2198\nEpoch 65/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 887ms/step - accuracy: 0.9987 - loss: 0.0046 - val_accuracy: 0.9566 - val_loss: 0.1933\nEpoch 66/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 887ms/step - accuracy: 0.9977 - loss: 0.0062 - val_accuracy: 0.8372 - val_loss: 0.8160\nEpoch 67/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 885ms/step - accuracy: 0.9973 - loss: 0.0060 - val_accuracy: 0.3643 - val_loss: 7.0517\nEpoch 68/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9822 - loss: 0.0408 - val_accuracy: 0.4946 - val_loss: 4.6432\nEpoch 69/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 885ms/step - accuracy: 0.9748 - loss: 0.0911 - val_accuracy: 0.4589 - val_loss: 122.2097\nEpoch 70/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 885ms/step - accuracy: 0.9753 - loss: 0.0614 - val_accuracy: 0.7256 - val_loss: 3.2157\nEpoch 71/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 885ms/step - accuracy: 0.9742 - loss: 0.0720 - val_accuracy: 0.8388 - val_loss: 1.1844\nEpoch 72/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 885ms/step - accuracy: 0.9907 - loss: 0.0271 - val_accuracy: 0.7984 - val_loss: 0.9769\nEpoch 73/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9839 - loss: 0.0441 - val_accuracy: 0.9132 - val_loss: 0.2955\nEpoch 74/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9965 - loss: 0.0134 - val_accuracy: 0.9550 - val_loss: 0.1789\nEpoch 75/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9970 - loss: 0.0103 - val_accuracy: 0.7845 - val_loss: 0.9525\nEpoch 76/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 885ms/step - accuracy: 0.9874 - loss: 0.0266 - val_accuracy: 0.5938 - val_loss: 3.0343\nEpoch 77/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9921 - loss: 0.0163 - val_accuracy: 0.7519 - val_loss: 1.1908\nEpoch 78/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9968 - loss: 0.0083 - val_accuracy: 0.9116 - val_loss: 0.3770\nEpoch 79/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9980 - loss: 0.0054 - val_accuracy: 0.9690 - val_loss: 0.1316\nEpoch 80/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 885ms/step - accuracy: 0.9985 - loss: 0.0045 - val_accuracy: 0.9101 - val_loss: 0.3620\nEpoch 81/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 885ms/step - accuracy: 0.9991 - loss: 0.0032 - val_accuracy: 0.9411 - val_loss: 0.2358\nEpoch 82/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9988 - loss: 0.0041 - val_accuracy: 0.8837 - val_loss: 0.4512\nEpoch 83/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 884ms/step - accuracy: 0.9945 - loss: 0.0181 - val_accuracy: 0.6481 - val_loss: 3.3024\nEpoch 84/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9966 - loss: 0.0100 - val_accuracy: 0.8279 - val_loss: 1.5064\nEpoch 85/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9940 - loss: 0.0156 - val_accuracy: 0.9426 - val_loss: 0.2301\nEpoch 86/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9960 - loss: 0.0135 - val_accuracy: 0.9194 - val_loss: 0.3327\nEpoch 87/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9929 - loss: 0.0232 - val_accuracy: 0.8357 - val_loss: 0.9627\nEpoch 88/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 885ms/step - accuracy: 0.9890 - loss: 0.0324 - val_accuracy: 0.8837 - val_loss: 0.4591\nEpoch 89/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9886 - loss: 0.0252 - val_accuracy: 0.9085 - val_loss: 0.3714\nEpoch 90/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 884ms/step - accuracy: 0.9916 - loss: 0.0234 - val_accuracy: 0.8295 - val_loss: 0.8409\nEpoch 91/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 884ms/step - accuracy: 0.9880 - loss: 0.0305 - val_accuracy: 0.8636 - val_loss: 0.6001\nEpoch 92/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 885ms/step - accuracy: 0.9879 - loss: 0.0262 - val_accuracy: 0.8899 - val_loss: 0.4762\nEpoch 93/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 885ms/step - accuracy: 0.9940 - loss: 0.0117 - val_accuracy: 0.9380 - val_loss: 0.2487\nEpoch 94/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 886ms/step - accuracy: 0.9968 - loss: 0.0124 - val_accuracy: 0.8326 - val_loss: 1.0101\nEpoch 95/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 887ms/step - accuracy: 0.9964 - loss: 0.0125 - val_accuracy: 0.8868 - val_loss: 0.4750\nEpoch 96/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 884ms/step - accuracy: 0.9963 - loss: 0.0141 - val_accuracy: 0.5535 - val_loss: 4.8426\nEpoch 97/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 885ms/step - accuracy: 0.9849 - loss: 0.0440 - val_accuracy: 0.7504 - val_loss: 1.4739\nEpoch 98/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 885ms/step - accuracy: 0.9930 - loss: 0.0223 - val_accuracy: 0.9209 - val_loss: 0.3920\nEpoch 99/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 885ms/step - accuracy: 0.9934 - loss: 0.0131 - val_accuracy: 0.9178 - val_loss: 0.3114\nEpoch 100/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 885ms/step - accuracy: 0.9980 - loss: 0.0079 - val_accuracy: 0.9519 - val_loss: 0.1942\nskip\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"a = 5\nwhile(True):\n    a = 10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T10:58:59.687277Z","iopub.execute_input":"2025-01-31T10:58:59.687590Z"}},"outputs":[],"execution_count":null}]}