{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":10602688,"sourceType":"datasetVersion","datasetId":6527737}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow import keras\nfrom keras.models import Model\nfrom keras import layers\nfrom keras.layers import Dense, Input, BatchNormalization, Activation\nfrom keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\n#from keras.applications.imagenet_utils import _obtain_input_shape\n#from keras.utils.data_utils import get_file\nfrom sklearn.model_selection import KFold\nfrom keras.datasets import mnist\nfrom PIL import Image\n# for creating a one hot vector for labels\n#from keras.utils import np_utils\nfrom IPython.display import display, Image\n#import the models\nfrom keras import Model\n#add layers\nfrom keras import layers\n#add optimizer\nfrom keras import optimizers\n#add loss function \nfrom keras import losses\nimport random\n\nimport keras\nimport numpy as np\nimport pandas as pd \nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nimport tensorflow.keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\n ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-30T13:20:24.324607Z","iopub.execute_input":"2025-01-30T13:20:24.324903Z","iopub.status.idle":"2025-01-30T13:20:37.140415Z","shell.execute_reply.started":"2025-01-30T13:20:24.324873Z","shell.execute_reply":"2025-01-30T13:20:37.139496Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"from tensorflow import keras\nfrom keras.models import Model\nfrom keras.layers import Dense, Input, BatchNormalization, Activation\nfrom keras.layers import Conv2D, SeparableConv2D, MaxPooling2D, GlobalAveragePooling2D\nfrom IPython.core.display import display, HTML\nimport sys\n\n# Adjust notebook display width\ndisplay(HTML(\"<style>.container { width:90% !important; }</style>\"))\n\n\nimg_size = 299\ndef Xception():\n\n\t# Determine proper input shape\n\tinput_shape = (img_size, img_size, 3 )#_obtain_input_shape(None, default_size=299, min_size=71, data_format='channels_last', include_top=False)\n\n\timg_input = Input(shape=input_shape)\n\n\t# Block 1\n\tx = Conv2D(32, (3, 3), strides=(2, 2), use_bias=False)(img_input)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = Conv2D(64, (3, 3), use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\n\tresidual = Conv2D(128, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n\tresidual = BatchNormalization()(residual)\n\n\t# Block 2\n\tx = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(128, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\n\t# Block 2 Pool\n\tx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\tx = layers.add([x, residual])\n\n\tresidual = Conv2D(256, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n\tresidual = BatchNormalization()(residual)\n\n\t# Block 3\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(256, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\n\t# Block 3 Pool\n\tx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\tx = layers.add([x, residual])\n\n\tresidual = Conv2D(728, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n\tresidual = BatchNormalization()(residual)\n\n\t# Block 4\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\n\tx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\tx = layers.add([x, residual])\n\n\t# Block 5 - 12\n\tfor i in range(8):\n\t\tresidual = x\n\n\t\tx = Activation('relu')(x)\n\t\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\t\tx = BatchNormalization()(x)\n\t\tx = Activation('relu')(x)\n\t\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\t\tx = BatchNormalization()(x)\n\t\tx = Activation('relu')(x)\n\t\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\t\tx = BatchNormalization()(x)\n\n\t\tx = layers.add([x, residual])\n\n\tresidual = Conv2D(1024, (1, 1), strides=(2, 2), padding='same', use_bias=False)(x)\n\tresidual = BatchNormalization()(residual)\n\n\t# Block 13\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(728, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\tx = SeparableConv2D(1024, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\n\t# Block 13 Pool\n\tx = MaxPooling2D((3, 3), strides=(2, 2), padding='same')(x)\n\tx = layers.add([x, residual])\n\n\t# Block 14\n\tx = SeparableConv2D(1536, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\n\t# Block 14 part 2\n\tx = SeparableConv2D(2048, (3, 3), padding='same', use_bias=False)(x)\n\tx = BatchNormalization()(x)\n\tx = Activation('relu')(x)\n\n\t# Fully Connected Layer\n\tx = GlobalAveragePooling2D()(x)\n\tx = Dense( 4 , activation='softmax')(x)\n\n\tinputs = img_input\n\n\t# Create model\n\tmodel = Model(inputs, x, name='xception')\n\n\t# Download and cache the Xception weights file\n\n\n\treturn model\n\nmodel = Xception()\n\nmodel.compile(\n    optimizer='Adam',\n    loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n    metrics=[\"accuracy\"],\n)\n\n# Print the model summary\nmodel.summary(print_fn=lambda x: sys.stdout.write(x + '\\n'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T13:20:37.141378Z","iopub.execute_input":"2025-01-30T13:20:37.141976Z","iopub.status.idle":"2025-01-30T13:20:40.195219Z","shell.execute_reply.started":"2025-01-30T13:20:37.141940Z","shell.execute_reply":"2025-01-30T13:20:40.191227Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style>.container { width:90% !important; }</style>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"},"metadata":{}},{"name":"stdout","text":"Model: \"xception\"\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n┃ Layer (type)              ┃ Output Shape           ┃        Param # ┃ Connected to           ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n│ input_layer (InputLayer)  │ (None, 299, 299, 3)    │              0 │ -                      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d (Conv2D)           │ (None, 149, 149, 32)   │            864 │ input_layer[0][0]      │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization       │ (None, 149, 149, 32)   │            128 │ conv2d[0][0]           │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation (Activation)   │ (None, 149, 149, 32)   │              0 │ batch_normalization[0… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_1 (Conv2D)         │ (None, 147, 147, 64)   │         18,432 │ activation[0][0]       │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_1     │ (None, 147, 147, 64)   │            256 │ conv2d_1[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_1 (Activation) │ (None, 147, 147, 64)   │              0 │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d          │ (None, 147, 147, 128)  │          8,768 │ activation_1[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_3     │ (None, 147, 147, 128)  │            512 │ separable_conv2d[0][0] │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_2 (Activation) │ (None, 147, 147, 128)  │              0 │ batch_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_1        │ (None, 147, 147, 128)  │         17,536 │ activation_2[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_4     │ (None, 147, 147, 128)  │            512 │ separable_conv2d_1[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_2 (Conv2D)         │ (None, 74, 74, 128)    │          8,192 │ activation_1[0][0]     │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d             │ (None, 74, 74, 128)    │              0 │ batch_normalization_4… │\n│ (MaxPooling2D)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_2     │ (None, 74, 74, 128)    │            512 │ conv2d_2[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add (Add)                 │ (None, 74, 74, 128)    │              0 │ max_pooling2d[0][0],   │\n│                           │                        │                │ batch_normalization_2… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_3 (Activation) │ (None, 74, 74, 128)    │              0 │ add[0][0]              │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_2        │ (None, 74, 74, 256)    │         33,920 │ activation_3[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_6     │ (None, 74, 74, 256)    │          1,024 │ separable_conv2d_2[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_4 (Activation) │ (None, 74, 74, 256)    │              0 │ batch_normalization_6… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_3        │ (None, 74, 74, 256)    │         67,840 │ activation_4[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_7     │ (None, 74, 74, 256)    │          1,024 │ separable_conv2d_3[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_3 (Conv2D)         │ (None, 37, 37, 256)    │         32,768 │ add[0][0]              │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_1           │ (None, 37, 37, 256)    │              0 │ batch_normalization_7… │\n│ (MaxPooling2D)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_5     │ (None, 37, 37, 256)    │          1,024 │ conv2d_3[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_1 (Add)               │ (None, 37, 37, 256)    │              0 │ max_pooling2d_1[0][0], │\n│                           │                        │                │ batch_normalization_5… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_5 (Activation) │ (None, 37, 37, 256)    │              0 │ add_1[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_4        │ (None, 37, 37, 728)    │        188,672 │ activation_5[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_9     │ (None, 37, 37, 728)    │          2,912 │ separable_conv2d_4[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_6 (Activation) │ (None, 37, 37, 728)    │              0 │ batch_normalization_9… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_5        │ (None, 37, 37, 728)    │        536,536 │ activation_6[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_10    │ (None, 37, 37, 728)    │          2,912 │ separable_conv2d_5[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_4 (Conv2D)         │ (None, 19, 19, 728)    │        186,368 │ add_1[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_2           │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (MaxPooling2D)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_8     │ (None, 19, 19, 728)    │          2,912 │ conv2d_4[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_2 (Add)               │ (None, 19, 19, 728)    │              0 │ max_pooling2d_2[0][0], │\n│                           │                        │                │ batch_normalization_8… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_7 (Activation) │ (None, 19, 19, 728)    │              0 │ add_2[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_6        │ (None, 19, 19, 728)    │        536,536 │ activation_7[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_11    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_6[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_8 (Activation) │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_7        │ (None, 19, 19, 728)    │        536,536 │ activation_8[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_12    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_7[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_9 (Activation) │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_8        │ (None, 19, 19, 728)    │        536,536 │ activation_9[0][0]     │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_13    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_8[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_3 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│                           │                        │                │ add_2[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_10             │ (None, 19, 19, 728)    │              0 │ add_3[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_9        │ (None, 19, 19, 728)    │        536,536 │ activation_10[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_14    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_9[0]… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_11             │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_10       │ (None, 19, 19, 728)    │        536,536 │ activation_11[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_15    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_10[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_12             │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_11       │ (None, 19, 19, 728)    │        536,536 │ activation_12[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_16    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_11[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_4 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│                           │                        │                │ add_3[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_13             │ (None, 19, 19, 728)    │              0 │ add_4[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_12       │ (None, 19, 19, 728)    │        536,536 │ activation_13[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_17    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_12[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_14             │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_13       │ (None, 19, 19, 728)    │        536,536 │ activation_14[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_18    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_13[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_15             │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_14       │ (None, 19, 19, 728)    │        536,536 │ activation_15[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_19    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_14[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_5 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_1… │\n│                           │                        │                │ add_4[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_16             │ (None, 19, 19, 728)    │              0 │ add_5[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_15       │ (None, 19, 19, 728)    │        536,536 │ activation_16[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_20    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_15[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_17             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_16       │ (None, 19, 19, 728)    │        536,536 │ activation_17[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_21    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_16[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_18             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_17       │ (None, 19, 19, 728)    │        536,536 │ activation_18[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_22    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_17[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_6 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│                           │                        │                │ add_5[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_19             │ (None, 19, 19, 728)    │              0 │ add_6[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_18       │ (None, 19, 19, 728)    │        536,536 │ activation_19[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_23    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_18[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_20             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_19       │ (None, 19, 19, 728)    │        536,536 │ activation_20[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_24    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_19[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_21             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_20       │ (None, 19, 19, 728)    │        536,536 │ activation_21[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_25    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_20[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_7 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│                           │                        │                │ add_6[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_22             │ (None, 19, 19, 728)    │              0 │ add_7[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_21       │ (None, 19, 19, 728)    │        536,536 │ activation_22[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_26    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_21[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_23             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_22       │ (None, 19, 19, 728)    │        536,536 │ activation_23[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_27    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_22[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_24             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_23       │ (None, 19, 19, 728)    │        536,536 │ activation_24[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_28    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_23[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_8 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│                           │                        │                │ add_7[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_25             │ (None, 19, 19, 728)    │              0 │ add_8[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_24       │ (None, 19, 19, 728)    │        536,536 │ activation_25[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_29    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_24[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_26             │ (None, 19, 19, 728)    │              0 │ batch_normalization_2… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_25       │ (None, 19, 19, 728)    │        536,536 │ activation_26[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_30    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_25[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_27             │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_26       │ (None, 19, 19, 728)    │        536,536 │ activation_27[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_31    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_26[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_9 (Add)               │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│                           │                        │                │ add_8[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_28             │ (None, 19, 19, 728)    │              0 │ add_9[0][0]            │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_27       │ (None, 19, 19, 728)    │        536,536 │ activation_28[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_32    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_27[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_29             │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_28       │ (None, 19, 19, 728)    │        536,536 │ activation_29[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_33    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_28[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_30             │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_29       │ (None, 19, 19, 728)    │        536,536 │ activation_30[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_34    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_29[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_10 (Add)              │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│                           │                        │                │ add_9[0][0]            │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_31             │ (None, 19, 19, 728)    │              0 │ add_10[0][0]           │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_30       │ (None, 19, 19, 728)    │        536,536 │ activation_31[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_36    │ (None, 19, 19, 728)    │          2,912 │ separable_conv2d_30[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_32             │ (None, 19, 19, 728)    │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_31       │ (None, 19, 19, 1024)   │        752,024 │ activation_32[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_37    │ (None, 19, 19, 1024)   │          4,096 │ separable_conv2d_31[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ conv2d_5 (Conv2D)         │ (None, 10, 10, 1024)   │        745,472 │ add_10[0][0]           │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ max_pooling2d_3           │ (None, 10, 10, 1024)   │              0 │ batch_normalization_3… │\n│ (MaxPooling2D)            │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_35    │ (None, 10, 10, 1024)   │          4,096 │ conv2d_5[0][0]         │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ add_11 (Add)              │ (None, 10, 10, 1024)   │              0 │ max_pooling2d_3[0][0], │\n│                           │                        │                │ batch_normalization_3… │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_32       │ (None, 10, 10, 1536)   │      1,582,080 │ add_11[0][0]           │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_38    │ (None, 10, 10, 1536)   │          6,144 │ separable_conv2d_32[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_33             │ (None, 10, 10, 1536)   │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ separable_conv2d_33       │ (None, 10, 10, 2048)   │      3,159,552 │ activation_33[0][0]    │\n│ (SeparableConv2D)         │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ batch_normalization_39    │ (None, 10, 10, 2048)   │          8,192 │ separable_conv2d_33[0… │\n│ (BatchNormalization)      │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ activation_34             │ (None, 10, 10, 2048)   │              0 │ batch_normalization_3… │\n│ (Activation)              │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ global_average_pooling2d  │ (None, 2048)           │              0 │ activation_34[0][0]    │\n│ (GlobalAveragePooling2D)  │                        │                │                        │\n├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n│ dense (Dense)             │ (None, 4)              │          8,196 │ global_average_poolin… │\n└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n Total params: 20,869,676 (79.61 MB)\n Trainable params: 20,815,148 (79.40 MB)\n Non-trainable params: 54,528 (213.00 KB)\n\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"x = []\nlabel = []\nx_validation = []\nlabel_validation = []\nx_test = []\nlabel_test = []\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T13:20:40.196124Z","iopub.execute_input":"2025-01-30T13:20:40.196434Z","iopub.status.idle":"2025-01-30T13:20:40.200495Z","shell.execute_reply.started":"2025-01-30T13:20:40.196397Z","shell.execute_reply":"2025-01-30T13:20:40.199720Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"csv_file = pd.read_csv(\"/kaggle/input/tea-image-dataset-nlmd-filtered/splited_into_5_fold.csv\")\nprint(csv_file)\n\nfolded = csv_file.groupby(\"fold\")\ntemp_image_name = \"\"\ntemp_image = []\nfor i,j in folded:\n    if i == 1: # testing\n        print(\"fold \"+str(i))\n        cat = j.groupby(\"category\")\n        for k,l in cat:\n            if k == \"Brown_blight\":\n                brown_blight_image_name = l['image_name']\n                brown_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Brown_blight\"\n                \n                for m in brown_blight_image_name:\n                    brown_blight_image = cv2.imread(brown_blight_link + '/'+\"nlmd_\"+m)\n                    brown_blight_image = cv2.resize( brown_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = brown_blight_image\n                    \"\"\"\n                    x_test.append(brown_blight_image)\n                    label_test.append([0])\n                print(len(x_test),\" \",len(label_test))\n                    \n            if k == \"Grey_blight\":\n                grey_blight_image_name = l['image_name']    \n                grey_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Grey_blight\"\n\n                for m in grey_blight_image_name:\n                    grey_blight_image = cv2.imread(grey_blight_link + '/'+\"nlmd_\"+m)\n                    grey_blight_image = cv2.resize( grey_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = grey_blight_image\n                    \"\"\"\n                    x_test.append(grey_blight_image)\n                    label_test.append([1])\n                print(len(x_test),\" \",len(label_test))\n                    \n            if k == \"Healthy\":\n                healthy_image_name = l['image_name']    \n                healthy_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Healthy\"\n\n                for m in healthy_image_name:\n                    healthy_image = cv2.imread(healthy_link + '/'+\"nlmd_\"+m)\n                    healthy_image = cv2.resize( healthy_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = healthy_image\n                    \"\"\"\n                    x_test.append( healthy_image)\n                    label_test.append([2])\n                print(len(x_test),\" \",len(label_test))\n\n            if k == \"Red_rust\":\n                red_rust_image_name = l['image_name']\n                red_rust_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Red_rust\"\n\n                for m in red_rust_image_name:\n                    red_rust_image = cv2.imread(red_rust_link+ '/' + \"nlmd_\"+m)\n                    red_rust_image = cv2.resize(red_rust_image, (img_size, img_size))\n                    x_test.append(red_rust_image)\n                    label_test.append([3])\n                print(len(x_test),\" \", len(label_test))\n            \n    \n    elif i == 2: # validation\n        print(\"fold \"+str(i))\n        cat = j.groupby(\"category\")\n        for k,l in cat:\n            if k == \"Brown_blight\":\n                brown_blight_image_name = l['image_name']\n                brown_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Brown_blight\"\n                \n                for m in brown_blight_image_name:\n                    brown_blight_image = cv2.imread(brown_blight_link + '/'+\"nlmd_\"+m)\n                    brown_blight_image = cv2.resize(brown_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = brown_blight_image\n                    \"\"\"\n                    x_validation.append(brown_blight_image)\n                    label_validation.append([0])\n                print(len(x_validation),\" \",len(label_validation))\n                    \n            if k == \"Grey_blight\":\n                grey_blight_image_name = l['image_name']    \n                grey_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Grey_blight\"\n\n                for m in grey_blight_image_name:\n                    grey_blight_image = cv2.imread(grey_blight_link + '/'+\"nlmd_\"+m)\n                    grey_blight_image = cv2.resize( grey_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = grey_blight_image\n                    \"\"\"\n                    x_validation.append(grey_blight_image)\n                    label_validation.append([1])\n                print(len(x_validation),\" \",len(label_validation))\n                    \n            if k == \"Healthy\":\n                healthy_image_name = l['image_name']    \n                healthy_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Healthy\"\n\n                for m in healthy_image_name:\n                    healthy_image = cv2.imread(healthy_link + '/'+\"nlmd_\"+m)\n                    healthy_image =  cv2.resize(healthy_image , ( img_size , img_size ))\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = healthy_image\n                    x_validation.append( healthy_image)\n                    label_validation.append([2])\n                print(len(x_validation),\" \",len(label_validation))\n                \n            if k == \"Red_rust\":\n                red_rust_image_name = l['image_name']\n                red_rust_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Red_rust\"\n\n                for m in red_rust_image_name:\n                    red_rust_image = cv2.imread(red_rust_link+ '/' + \"nlmd_\"+m)\n                    red_rust_image = cv2.resize(red_rust_image, (img_size, img_size))\n                    x_validation.append(red_rust_image)\n                    label_validation.append([3])\n                print(len(x_validation),\" \", len(label_validation))\n            \n\n    else: # training\n        print(\"fold \"+str(i))\n        cat = j.groupby(\"category\")\n        for k,l in cat:\n            if k == \"Brown_blight\":\n                brown_blight_image_name = l['image_name']\n                brown_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Brown_blight\"\n                \n                for m in brown_blight_image_name:\n                    brown_blight_image = cv2.imread(brown_blight_link + '/'+\"nlmd_\"+m)\n                    brown_blight_image = cv2.resize(brown_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = brown_blight_image\n                    \"\"\"\n                    x.append(brown_blight_image)\n                    label.append([0])\n                print(len(x),\" \",len(label))\n            if k == \"Grey_blight\":\n                grey_blight_image_name = l['image_name']    \n                grey_blight_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Grey_blight\"\n\n                for m in grey_blight_image_name:\n                    grey_blight_image = cv2.imread(grey_blight_link + '/'+\"nlmd_\"+m)\n                    grey_blight_image = cv2.resize( grey_blight_image , ( img_size , img_size ))\n                    \"\"\"\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = grey_blight_image\n                    \"\"\"\n                    x.append(grey_blight_image)\n                    label.append([1])\n                print(len(x),\" \",len(label))\n                    \n            if k == \"Healthy\":\n                healthy_image_name = l['image_name']    \n                healthy_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Healthy\"\n\n                for m in healthy_image_name:\n                    healthy_image = cv2.imread(healthy_link + '/'+\"nlmd_\"+m)\n                    healthy_image =  cv2.resize(healthy_image , ( img_size , img_size ))\n                    if len(temp_image) == 0:\n                        temp_image_name = m\n                        temp_image = healthy_image\n                    x.append( healthy_image)\n                    label.append([2])\n                print(len(x),\" \",len(label))\n                \n            if k == \"Red_rust\":\n                red_rust_image_name = l['image_name']\n                red_rust_link = \"/kaggle/input/tea-image-dataset-nlmd-filtered/filtered/filtered/non_local_means_denoising/Red_rust\"\n\n                for m in red_rust_image_name:\n                    red_rust_image = cv2.imread(red_rust_link+ '/' + \"nlmd_\"+m)\n                    red_rust_image = cv2.resize(red_rust_image, (img_size, img_size))\n                    x.append(red_rust_image)\n                    label.append([3])\n                print(len(x),\" \", len(label))\n            \n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T13:20:40.203015Z","iopub.execute_input":"2025-01-30T13:20:40.203337Z","iopub.status.idle":"2025-01-30T13:24:10.289481Z","shell.execute_reply.started":"2025-01-30T13:20:40.203300Z","shell.execute_reply":"2025-01-30T13:24:10.288434Z"}},"outputs":[{"name":"stdout","text":"                 image_name  fold      category\n0      Training_img_280.jpg     0  Brown_blight\n1      Training_img_662.jpg     0  Brown_blight\n2      Training_img_651.jpg     0  Brown_blight\n3      Training_img_809.jpg     0  Brown_blight\n4      Training_img_546.jpg     0  Brown_blight\n...                     ...   ...           ...\n3229  Training_img_2989.jpg     4      Red_rust\n3230  Training_img_2880.jpg     4      Red_rust\n3231  Training_img_2693.jpg     4      Red_rust\n3232  Training_img_2997.jpg     4      Red_rust\n3233  Training_img_2993.jpg     4      Red_rust\n\n[3234 rows x 3 columns]\nfold 0\n159   159\n329   329\n491   491\n649   649\nfold 1\n159   159\n328   328\n490   490\n648   648\nfold 2\n158   158\n327   327\n489   489\n646   646\nfold 3\n807   807\n976   976\n1138   1138\n1295   1295\nfold 4\n1453   1453\n1622   1622\n1783   1783\n1940   1940\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"print(len(x),\" \",len(label))\nprint(len(x_validation),\" \",len(label_validation))\nprint(len(x_test),\" \",len(label_test))\nprint(\"Hello world.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T13:24:10.290988Z","iopub.execute_input":"2025-01-30T13:24:10.291232Z","iopub.status.idle":"2025-01-30T13:24:10.297811Z","shell.execute_reply.started":"2025-01-30T13:24:10.291200Z","shell.execute_reply":"2025-01-30T13:24:10.297089Z"}},"outputs":[{"name":"stdout","text":"1940   1940\n646   646\n648   648\nHello world.\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"x = np.asarray(x)\nx_validation = np.asarray(x_validation)\nx_test = np.asarray(x_test)\n\nprint(len(x),\" \", len(x_validation),\" \", len(x_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T13:24:10.298588Z","iopub.execute_input":"2025-01-30T13:24:10.298853Z","iopub.status.idle":"2025-01-30T13:24:10.550747Z","shell.execute_reply.started":"2025-01-30T13:24:10.298833Z","shell.execute_reply":"2025-01-30T13:24:10.549870Z"}},"outputs":[{"name":"stdout","text":"1940   646   648\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical \n\nlabel = np.array(label)\nlabel = to_categorical(label , 4 )\nprint(len(label))\n\n\n\nlabel = np.array(label)\nlabel_validation = to_categorical(label_validation , 4 )\nprint(len(label_validation))\n\nlabel = np.array(label)\nlabel_test = to_categorical(label_test , 4 )\nprint(len(label_test))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T13:24:10.551578Z","iopub.execute_input":"2025-01-30T13:24:10.551919Z","iopub.status.idle":"2025-01-30T13:24:10.561952Z","shell.execute_reply.started":"2025-01-30T13:24:10.551888Z","shell.execute_reply":"2025-01-30T13:24:10.561118Z"}},"outputs":[{"name":"stdout","text":"1940\n646\n648\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"print(label[491])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T13:24:10.562561Z","iopub.execute_input":"2025-01-30T13:24:10.562817Z","iopub.status.idle":"2025-01-30T13:24:10.573293Z","shell.execute_reply.started":"2025-01-30T13:24:10.562799Z","shell.execute_reply":"2025-01-30T13:24:10.572487Z"}},"outputs":[{"name":"stdout","text":"[0. 0. 0. 1.]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"early_stop  = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience= 90 , verbose=0, mode='max')\n#check_point = tf.keras.callbacks.ModelCheckpoint('/kaggle/working/xception_tea_leaves_nlmd_filtered.h5', monitor='val_acc', save_best_only=True, mode='max')\ncheck_point = tf.keras.callbacks.ModelCheckpoint('/kaggle/working/xception_tea_leaves_nlmd_filtered_1_2.keras', monitor='val_accuracy', save_best_only=True, mode='max')\n\nhistory = model.fit(x , label , validation_data = (x_validation , label_validation ), epochs = 100 , callbacks=[early_stop, check_point])\n    \n\nprint(\"skip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T13:24:10.574094Z","iopub.execute_input":"2025-01-30T13:24:10.574321Z","iopub.status.idle":"2025-01-30T15:15:12.391508Z","shell.execute_reply.started":"2025-01-30T13:24:10.574302Z","shell.execute_reply":"2025-01-30T15:15:12.390734Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 2s/step - accuracy: 0.5530 - loss: 1.0592 - val_accuracy: 0.2616 - val_loss: 1.3854\nEpoch 2/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.8447 - loss: 0.3904 - val_accuracy: 0.2616 - val_loss: 1.3872\nEpoch 3/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.8480 - loss: 0.3541 - val_accuracy: 0.2570 - val_loss: 1.3845\nEpoch 4/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.8817 - loss: 0.3087 - val_accuracy: 0.2693 - val_loss: 1.3938\nEpoch 5/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9341 - loss: 0.1814 - val_accuracy: 0.2430 - val_loss: 1.6078\nEpoch 6/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9195 - loss: 0.2047 - val_accuracy: 0.2508 - val_loss: 1.8581\nEpoch 7/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9378 - loss: 0.1629 - val_accuracy: 0.3839 - val_loss: 1.4502\nEpoch 8/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9008 - loss: 0.2110 - val_accuracy: 0.8375 - val_loss: 0.4341\nEpoch 9/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9570 - loss: 0.1251 - val_accuracy: 0.6316 - val_loss: 1.1851\nEpoch 10/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9435 - loss: 0.1379 - val_accuracy: 0.7817 - val_loss: 0.7832\nEpoch 11/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9590 - loss: 0.1106 - val_accuracy: 0.4830 - val_loss: 2.7902\nEpoch 12/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9696 - loss: 0.0993 - val_accuracy: 0.3282 - val_loss: 6.9559\nEpoch 13/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9728 - loss: 0.0789 - val_accuracy: 0.7879 - val_loss: 1.5016\nEpoch 14/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9804 - loss: 0.0633 - val_accuracy: 0.6687 - val_loss: 3.0926\nEpoch 15/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9724 - loss: 0.0849 - val_accuracy: 0.8715 - val_loss: 0.6347\nEpoch 16/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9724 - loss: 0.0809 - val_accuracy: 0.8545 - val_loss: 0.6915\nEpoch 17/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9466 - loss: 0.1600 - val_accuracy: 0.8359 - val_loss: 0.7059\nEpoch 18/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - accuracy: 0.9708 - loss: 0.0730 - val_accuracy: 0.8684 - val_loss: 0.5093\nEpoch 19/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9760 - loss: 0.0582 - val_accuracy: 0.7136 - val_loss: 1.2881\nEpoch 20/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9795 - loss: 0.0689 - val_accuracy: 0.7276 - val_loss: 1.4686\nEpoch 21/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9842 - loss: 0.0476 - val_accuracy: 0.8916 - val_loss: 0.4493\nEpoch 22/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9790 - loss: 0.0741 - val_accuracy: 0.9474 - val_loss: 0.1427\nEpoch 23/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9915 - loss: 0.0313 - val_accuracy: 0.9040 - val_loss: 0.4410\nEpoch 24/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9579 - loss: 0.1345 - val_accuracy: 0.4706 - val_loss: 9.5936\nEpoch 25/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - accuracy: 0.9579 - loss: 0.1307 - val_accuracy: 0.7709 - val_loss: 1.2875\nEpoch 26/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9788 - loss: 0.0572 - val_accuracy: 0.9087 - val_loss: 0.4224\nEpoch 27/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9647 - loss: 0.0862 - val_accuracy: 0.8251 - val_loss: 0.6273\nEpoch 28/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9899 - loss: 0.0301 - val_accuracy: 0.8235 - val_loss: 1.1117\nEpoch 29/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9826 - loss: 0.0533 - val_accuracy: 0.8313 - val_loss: 0.6398\nEpoch 30/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9819 - loss: 0.0478 - val_accuracy: 0.9551 - val_loss: 0.1219\nEpoch 31/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9846 - loss: 0.0400 - val_accuracy: 0.9211 - val_loss: 0.2850\nEpoch 32/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9784 - loss: 0.0687 - val_accuracy: 0.8963 - val_loss: 0.3668\nEpoch 33/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9920 - loss: 0.0233 - val_accuracy: 0.9025 - val_loss: 0.4265\nEpoch 34/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9941 - loss: 0.0194 - val_accuracy: 0.8963 - val_loss: 0.4195\nEpoch 35/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9915 - loss: 0.0256 - val_accuracy: 0.8793 - val_loss: 0.6000\nEpoch 36/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9907 - loss: 0.0339 - val_accuracy: 0.8669 - val_loss: 0.3864\nEpoch 37/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9910 - loss: 0.0266 - val_accuracy: 0.7229 - val_loss: 1.6208\nEpoch 38/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9935 - loss: 0.0251 - val_accuracy: 0.9195 - val_loss: 0.2461\nEpoch 39/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9948 - loss: 0.0162 - val_accuracy: 0.9025 - val_loss: 0.4125\nEpoch 40/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9985 - loss: 0.0081 - val_accuracy: 0.9381 - val_loss: 0.2400\nEpoch 41/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - accuracy: 0.9992 - loss: 0.0088 - val_accuracy: 0.9536 - val_loss: 0.1474\nEpoch 42/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9944 - loss: 0.0144 - val_accuracy: 0.9690 - val_loss: 0.0913\nEpoch 43/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9958 - loss: 0.0144 - val_accuracy: 0.9365 - val_loss: 0.2094\nEpoch 44/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9935 - loss: 0.0215 - val_accuracy: 0.8406 - val_loss: 0.7454\nEpoch 45/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9851 - loss: 0.0442 - val_accuracy: 0.8127 - val_loss: 1.1716\nEpoch 46/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9821 - loss: 0.0451 - val_accuracy: 0.8220 - val_loss: 0.8047\nEpoch 47/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9872 - loss: 0.0264 - val_accuracy: 0.5093 - val_loss: 8.2296\nEpoch 48/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9904 - loss: 0.0434 - val_accuracy: 0.9040 - val_loss: 0.4209\nEpoch 49/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9857 - loss: 0.0459 - val_accuracy: 0.4659 - val_loss: 4.2377\nEpoch 50/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9820 - loss: 0.0600 - val_accuracy: 0.8467 - val_loss: 0.9252\nEpoch 51/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9881 - loss: 0.0366 - val_accuracy: 0.8080 - val_loss: 0.9590\nEpoch 52/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9726 - loss: 0.0833 - val_accuracy: 0.7740 - val_loss: 2.0114\nEpoch 53/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9937 - loss: 0.0195 - val_accuracy: 0.6238 - val_loss: 2.1707\nEpoch 54/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9921 - loss: 0.0261 - val_accuracy: 0.9567 - val_loss: 0.1404\nEpoch 55/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9906 - loss: 0.0256 - val_accuracy: 0.9241 - val_loss: 0.3097\nEpoch 56/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9949 - loss: 0.0194 - val_accuracy: 0.9040 - val_loss: 0.4444\nEpoch 57/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9883 - loss: 0.0269 - val_accuracy: 0.9598 - val_loss: 0.1543\nEpoch 58/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9897 - loss: 0.0296 - val_accuracy: 0.9489 - val_loss: 0.1747\nEpoch 59/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9924 - loss: 0.0217 - val_accuracy: 0.9226 - val_loss: 0.2916\nEpoch 60/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9860 - loss: 0.0480 - val_accuracy: 0.8034 - val_loss: 1.0790\nEpoch 61/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9970 - loss: 0.0105 - val_accuracy: 0.6672 - val_loss: 3.9981\nEpoch 62/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 1s/step - accuracy: 0.9959 - loss: 0.0094 - val_accuracy: 0.9783 - val_loss: 0.0750\nEpoch 63/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 1s/step - accuracy: 0.9964 - loss: 0.0066 - val_accuracy: 0.9814 - val_loss: 0.1127\nEpoch 64/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9947 - loss: 0.0172 - val_accuracy: 0.7879 - val_loss: 1.1406\nEpoch 65/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9928 - loss: 0.0205 - val_accuracy: 0.9427 - val_loss: 0.2269\nEpoch 66/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 1s/step - accuracy: 0.9917 - loss: 0.0204 - val_accuracy: 0.6780 - val_loss: 1.6561\nEpoch 67/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9954 - loss: 0.0150 - val_accuracy: 0.7848 - val_loss: 1.2187\nEpoch 68/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9986 - loss: 0.0088 - val_accuracy: 0.9164 - val_loss: 0.3461\nEpoch 69/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9977 - loss: 0.0061 - val_accuracy: 0.8576 - val_loss: 0.8457\nEpoch 70/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9960 - loss: 0.0096 - val_accuracy: 0.8282 - val_loss: 1.0459\nEpoch 71/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9934 - loss: 0.0181 - val_accuracy: 0.8870 - val_loss: 0.5044\nEpoch 72/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9923 - loss: 0.0264 - val_accuracy: 0.8065 - val_loss: 0.8602\nEpoch 73/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9823 - loss: 0.0509 - val_accuracy: 0.7879 - val_loss: 1.6521\nEpoch 74/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9912 - loss: 0.0252 - val_accuracy: 0.9381 - val_loss: 0.2660\nEpoch 75/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9915 - loss: 0.0285 - val_accuracy: 0.8266 - val_loss: 1.5163\nEpoch 76/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9947 - loss: 0.0141 - val_accuracy: 0.8065 - val_loss: 1.3309\nEpoch 77/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9964 - loss: 0.0135 - val_accuracy: 0.9520 - val_loss: 0.1699\nEpoch 78/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9961 - loss: 0.0133 - val_accuracy: 0.8808 - val_loss: 0.4749\nEpoch 79/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9916 - loss: 0.0259 - val_accuracy: 0.5279 - val_loss: 3.8008\nEpoch 80/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9816 - loss: 0.0870 - val_accuracy: 0.6037 - val_loss: 3.9360\nEpoch 81/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9727 - loss: 0.0663 - val_accuracy: 0.5650 - val_loss: 7.3567\nEpoch 82/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9847 - loss: 0.0369 - val_accuracy: 0.8498 - val_loss: 0.6982\nEpoch 83/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9797 - loss: 0.0605 - val_accuracy: 0.8808 - val_loss: 0.6695\nEpoch 84/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9953 - loss: 0.0173 - val_accuracy: 0.7678 - val_loss: 1.1566\nEpoch 85/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9922 - loss: 0.0230 - val_accuracy: 0.9458 - val_loss: 0.2583\nEpoch 86/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9926 - loss: 0.0205 - val_accuracy: 0.4025 - val_loss: 7.2311\nEpoch 87/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9945 - loss: 0.0236 - val_accuracy: 0.9489 - val_loss: 0.1709\nEpoch 88/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9961 - loss: 0.0146 - val_accuracy: 0.8824 - val_loss: 0.4318\nEpoch 89/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9936 - loss: 0.0137 - val_accuracy: 0.9458 - val_loss: 0.1685\nEpoch 90/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9919 - loss: 0.0188 - val_accuracy: 0.8050 - val_loss: 0.6836\nEpoch 91/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9912 - loss: 0.0273 - val_accuracy: 0.9102 - val_loss: 0.2683\nEpoch 92/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9916 - loss: 0.0275 - val_accuracy: 0.8220 - val_loss: 1.7360\nEpoch 93/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9985 - loss: 0.0067 - val_accuracy: 0.9752 - val_loss: 0.0775\nEpoch 94/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9950 - loss: 0.0120 - val_accuracy: 0.8467 - val_loss: 0.4643\nEpoch 95/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9965 - loss: 0.0098 - val_accuracy: 0.9536 - val_loss: 0.1505\nEpoch 96/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9981 - loss: 0.0054 - val_accuracy: 0.9675 - val_loss: 0.0870\nEpoch 97/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9923 - loss: 0.0197 - val_accuracy: 0.9505 - val_loss: 0.1963\nEpoch 98/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9947 - loss: 0.0157 - val_accuracy: 0.8375 - val_loss: 0.6795\nEpoch 99/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9959 - loss: 0.0138 - val_accuracy: 0.3483 - val_loss: 5.8648\nEpoch 100/100\n\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 1s/step - accuracy: 0.9922 - loss: 0.0198 - val_accuracy: 0.3498 - val_loss: 25.9088\nskip\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"a = 5\nwhile(True):\n    a = 10","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-30T15:15:12.392349Z","iopub.execute_input":"2025-01-30T15:15:12.392676Z"}},"outputs":[],"execution_count":null}]}